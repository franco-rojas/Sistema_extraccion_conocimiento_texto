{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "722e530a",
   "metadata": {},
   "source": [
    "### Master oficial en Big Data & Data Science - Universidad Internacional de Valencia (VIU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25bfaf",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\">\n",
    "\n",
    "-   **Alumno:** Franco Rojas Yucra\n",
    "-   **TFM:** Sistema para la busqueda de conocimientos en textos de documentos multimedia\n",
    "-   **Email:** franco.rojasyucra@alumnos.viu.es\n",
    "-   **Fecha:** Octubre de 2023\n",
    "<font color=\"black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8669b20",
   "metadata": {},
   "source": [
    "## 08 Human evaluation para modelos de lenguaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de53580",
   "metadata": {},
   "source": [
    "Librerías utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4579b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain import PromptTemplate\n",
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d541cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None) #motrar todas las columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86d112",
   "metadata": {},
   "source": [
    "Lista de preguntas que evaluaran a los modelos de lenguaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9e3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quest=pd.read_excel('human_evaluation/Question_Answers_Human.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "090706f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_hquest</th>\n",
       "      <th>human_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QU01</td>\n",
       "      <td>¿Que son Embeddings?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QU02</td>\n",
       "      <td>¿Que es BigData?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QU03</td>\n",
       "      <td>¿Qué es el Internet de las Cosas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QU04</td>\n",
       "      <td>¿Qué son los actuadores?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QU05</td>\n",
       "      <td>¿Qué es un sensor?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_hquest                     human_question\n",
       "0      QU01               ¿Que son Embeddings?\n",
       "1      QU02                   ¿Que es BigData?\n",
       "2      QU03  ¿Qué es el Internet de las Cosas?\n",
       "3      QU04           ¿Qué son los actuadores?\n",
       "4      QU05                 ¿Qué es un sensor?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c8b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para retirar codigos de template\n",
    "def answer_str(question,txt_lg):\n",
    "    txt1=re.sub(question, '', txt_lg)\n",
    "    txt2=re.sub(f'<|assistant|>', '', txt1)\n",
    "    txt3=re.sub(f'<|prompter|>', '', txt2)\n",
    "    txt_resp=re.sub('[%s]' % re.escape('?¿|'), '', txt3)\n",
    "    return txt_resp.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4eb748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fdbeca9",
   "metadata": {},
   "source": [
    "#### 1. Generando respues de modelo BLOOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c77058",
   "metadata": {},
   "source": [
    "Lectura de modelo con HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fb667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franco\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c8946f1f3f4f94a8df985aea513586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franco\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Franco\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76919b4cc3f6404e98f4faa3b013f663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b0d447f7d54367ac4f18ade5cbb168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f0c19de65046ee9c1f339a43abddae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/783 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd865943d2643258954ef95a69c9271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/4.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33fc047b824415299a43f4706563ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(model_id=\"franco-rojas/bloom-1b1-finetuned-tfmviu\",\n",
    "                                        task=\"text-generation\",\n",
    "                                        model_kwargs={\"temperature\": 0.2, \"max_length\": 200})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60023057",
   "metadata": {},
   "source": [
    "Template que ayuda a generar pregunta y respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0b40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"<|prompter|>{question}<|endoftext|><|assistant|>\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e9090e",
   "metadata": {},
   "source": [
    "Generando respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0f3d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franco\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "C:\\Users\\Franco\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1369: UserWarning: Using `max_length`'s default (200) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU01 finalizado\n",
      "QU02 finalizado\n",
      "QU03 finalizado\n",
      "QU04 finalizado\n",
      "QU05 finalizado\n",
      "QU06 finalizado\n",
      "QU07 finalizado\n",
      "QU08 finalizado\n",
      "QU09 finalizado\n",
      "QU10 finalizado\n",
      "QU11 finalizado\n",
      "QU12 finalizado\n",
      "QU13 finalizado\n",
      "QU14 finalizado\n",
      "QU15 finalizado\n",
      "QU16 finalizado\n",
      "QU17 finalizado\n",
      "QU18 finalizado\n",
      "QU19 finalizado\n",
      "QU20 finalizado\n",
      "QU21 finalizado\n",
      "QU22 finalizado\n",
      "QU23 finalizado\n",
      "QU24 finalizado\n",
      "QU25 finalizado\n",
      "CPU times: total: 29min 57s\n",
      "Wall time: 17min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_answer_mod=pd.DataFrame()\n",
    "for idq,quest in zip(list(df_quest.id_hquest),list(df_quest.human_question)):\n",
    "    answ=llm_chain.run(quest)\n",
    "    df_ans_t=pd.DataFrame({'id_hquest':[idq],'human_question':[quest],'answer_mod':[answer_str(quest,answ)]})\n",
    "    df_answer_mod=pd.concat([df_answer_mod,df_ans_t]).reset_index(drop=True)\n",
    "    df_answer_mod.to_excel('human_evaluation/Answers_Model_BLOOM.xlsx',index=False)\n",
    "    print(idq+' finalizado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c48f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18111c42",
   "metadata": {},
   "source": [
    "#### 2. Generando respues de modelo Falcon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c8f0f",
   "metadata": {},
   "source": [
    "Lectura de modelo con HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9ffcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franco\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(model_id=\"franco-rojas/falcon-rw-1b-finetuned-tfmviu\",\n",
    "                                        task=\"text-generation\",\n",
    "                                        model_kwargs={\"temperature\": 0.2, \"max_length\": 200})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bc451",
   "metadata": {},
   "source": [
    "Template que ayuda a generar pregunta y respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d04b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"<|prompter|>{question}<|endoftext|><|assistant|>\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599e404",
   "metadata": {},
   "source": [
    "Generando respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffab4a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU01 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU02 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU03 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU04 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU05 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU06 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU07 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU08 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU09 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU10 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU11 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU12 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU13 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU14 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU15 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU16 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU17 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU18 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU19 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU20 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU21 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU22 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU23 finalizado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QU24 finalizado\n",
      "QU25 finalizado\n",
      "CPU times: total: 36min 28s\n",
      "Wall time: 19min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_answer_mod=pd.DataFrame()\n",
    "for idq,quest in zip(list(df_quest.id_hquest),list(df_quest.human_question)):\n",
    "    answ=llm_chain.run(quest)\n",
    "    df_ans_t=pd.DataFrame({'id_hquest':[idq],'human_question':[quest],'answer_mod':[answer_str(quest,answ)]})\n",
    "    df_answer_mod=pd.concat([df_answer_mod,df_ans_t]).reset_index(drop=True)\n",
    "    df_answer_mod.to_excel('human_evaluation/Answers_Model_Falcon.xlsx',index=False)\n",
    "    print(idq+' finalizado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199a392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24a606a9",
   "metadata": {},
   "source": [
    "##### Uniendo respuestas en un solo dataset para enviar a evaluadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6535026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volviendo a leer las hojas de calculo generadas en anteriores pasos\n",
    "df_qa_bloom=pd.read_excel('human_evaluation/Answers_Model_BLOOM.xlsx')\n",
    "df_qa_falcon=pd.read_excel('human_evaluation/Answers_Model_Falcon.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6162b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_bloom['bloom_eval1']=''\n",
    "df_qa_bloom['bloom_eval2']=''\n",
    "df_qa_bloom.columns=['id_hquest', 'human_question', 'bloom_answer', 'bl_gr','bl_gr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79eda1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_falcon['falcon_eval1']=''\n",
    "df_qa_falcon['falcon_eval2']=''\n",
    "df_qa_falcon.columns=['id_hquest', 'human_question', 'falcon_answer', 'fa_gr','fa_coh']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8de39a",
   "metadata": {},
   "source": [
    "Preparando hoja de calculo para evaluación humana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1659b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human_eval=pd.merge(df_qa_bloom,df_qa_falcon,how='left',on=['id_hquest','human_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ca221b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_hquest</th>\n",
       "      <th>human_question</th>\n",
       "      <th>bloom_answer</th>\n",
       "      <th>bl_gr</th>\n",
       "      <th>bl_gr</th>\n",
       "      <th>falcon_answer</th>\n",
       "      <th>fa_gr</th>\n",
       "      <th>fa_coh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QU01</td>\n",
       "      <td>¿Que son Embeddings?</td>\n",
       "      <td>Cuando hablamos de embeddings en general nos r...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Qué es una presentación digital Una presentaci...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QU02</td>\n",
       "      <td>¿Que es BigData?</td>\n",
       "      <td>Que es un Data Lakedreamspeakspeakerspeakerspe...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>El lenguaje natural es un lenguaje que se pued...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QU03</td>\n",
       "      <td>¿Qué es el Internet de las Cosas?</td>\n",
       "      <td>El Internet de las Cosas es un concepto que ya...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>es una herramienta de inteligencia artificial ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QU04</td>\n",
       "      <td>¿Qué son los actuadores?</td>\n",
       "      <td>Los actuadores son las partes del programa que...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pues realmente es capaz de hacer cosas que un ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QU05</td>\n",
       "      <td>¿Qué es un sensor?</td>\n",
       "      <td>Qué es un actuadorQué es un controladorQué es ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>es una herramienta de inteligencia artificial ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QU06</td>\n",
       "      <td>¿Cuál es el objetivo de Deep Learning?</td>\n",
       "      <td>Cuál es el uso real de Deep Learningspeakspeak...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>es una herramienta de inteligencia artificial ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QU07</td>\n",
       "      <td>¿Cuáles son algunas aplicaciones de la Intelig...</td>\n",
       "      <td>Cuál es el futuro de la Inteligencia Artificia...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>El aprendizaje automático puede ser utilizado ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QU08</td>\n",
       "      <td>¿Qué son los tokens?</td>\n",
       "      <td>Los tokens son como pequeños pedazos de texto ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>es una herramienta de inteligencia artificial ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QU09</td>\n",
       "      <td>¿Cuándo usar Hadoop?</td>\n",
       "      <td>Qué es HadoopadoopapacheQué es Apache Hadoopap...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hadoop es un framework que permite el procesam...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>QU10</td>\n",
       "      <td>¿Que es un transformer?</td>\n",
       "      <td>Un transformer es un tipo de algoritmo que per...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Qué es una inteligencia artificial Una intelig...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_hquest                                     human_question  \\\n",
       "0      QU01                               ¿Que son Embeddings?   \n",
       "1      QU02                                   ¿Que es BigData?   \n",
       "2      QU03                  ¿Qué es el Internet de las Cosas?   \n",
       "3      QU04                           ¿Qué son los actuadores?   \n",
       "4      QU05                                 ¿Qué es un sensor?   \n",
       "5      QU06             ¿Cuál es el objetivo de Deep Learning?   \n",
       "6      QU07  ¿Cuáles son algunas aplicaciones de la Intelig...   \n",
       "7      QU08                               ¿Qué son los tokens?   \n",
       "8      QU09                               ¿Cuándo usar Hadoop?   \n",
       "9      QU10                            ¿Que es un transformer?   \n",
       "\n",
       "                                        bloom_answer bl_gr bl_gr  \\\n",
       "0  Cuando hablamos de embeddings en general nos r...               \n",
       "1  Que es un Data Lakedreamspeakspeakerspeakerspe...               \n",
       "2  El Internet de las Cosas es un concepto que ya...               \n",
       "3  Los actuadores son las partes del programa que...               \n",
       "4  Qué es un actuadorQué es un controladorQué es ...               \n",
       "5  Cuál es el uso real de Deep Learningspeakspeak...               \n",
       "6  Cuál es el futuro de la Inteligencia Artificia...               \n",
       "7  Los tokens son como pequeños pedazos de texto ...               \n",
       "8  Qué es HadoopadoopapacheQué es Apache Hadoopap...               \n",
       "9  Un transformer es un tipo de algoritmo que per...               \n",
       "\n",
       "                                       falcon_answer fa_gr fa_coh  \n",
       "0  Qué es una presentación digital Una presentaci...               \n",
       "1  El lenguaje natural es un lenguaje que se pued...               \n",
       "2  es una herramienta de inteligencia artificial ...               \n",
       "3  Pues realmente es capaz de hacer cosas que un ...               \n",
       "4  es una herramienta de inteligencia artificial ...               \n",
       "5  es una herramienta de inteligencia artificial ...               \n",
       "6  El aprendizaje automático puede ser utilizado ...               \n",
       "7  es una herramienta de inteligencia artificial ...               \n",
       "8  Hadoop es un framework que permite el procesam...               \n",
       "9  Qué es una inteligencia artificial Una intelig...               "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_eval.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8ee06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human_eval.to_excel('human_evaluation/Formato_Human_Evaluation.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9855fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "723e1bec",
   "metadata": {},
   "source": [
    "##### Lectura de hojas de calculo con puntajes de evaluadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbc6374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heval=pd.DataFrame()\n",
    "for x in ['Evaluador1','Evaluador2','Evaluador3']:\n",
    "    df_evalt=pd.read_excel('human_evaluation/Results_Human_Evaluation.xlsx')\n",
    "    df_heval=pd.concat([df_heval,df_evalt]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92f57c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_hquest</th>\n",
       "      <th>human_question</th>\n",
       "      <th>bloom_answer</th>\n",
       "      <th>bl_gr</th>\n",
       "      <th>bl_coh</th>\n",
       "      <th>falcon_answer</th>\n",
       "      <th>fa_gr</th>\n",
       "      <th>fa_coh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QU01</td>\n",
       "      <td>¿Que son Embeddings?</td>\n",
       "      <td>Cuando hablamos de embeddings en general nos r...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Qué es una presentación digital Una presentaci...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QU02</td>\n",
       "      <td>¿Que es BigData?</td>\n",
       "      <td>Que es un Data Lakedreamspeakspeakerspeakerspe...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>El lenguaje natural es un lenguaje que se pued...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QU03</td>\n",
       "      <td>¿Qué es el Internet de las Cosas?</td>\n",
       "      <td>El Internet de las Cosas es un concepto que ya...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>es una herramienta de inteligencia artificial ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_hquest                     human_question  \\\n",
       "0      QU01               ¿Que son Embeddings?   \n",
       "1      QU02                   ¿Que es BigData?   \n",
       "2      QU03  ¿Qué es el Internet de las Cosas?   \n",
       "\n",
       "                                        bloom_answer  bl_gr  bl_coh  \\\n",
       "0  Cuando hablamos de embeddings en general nos r...      5       4   \n",
       "1  Que es un Data Lakedreamspeakspeakerspeakerspe...      2       2   \n",
       "2  El Internet de las Cosas es un concepto que ya...      5       4   \n",
       "\n",
       "                                       falcon_answer  fa_gr  fa_coh  \n",
       "0  Qué es una presentación digital Una presentaci...      2       1  \n",
       "1  El lenguaje natural es un lenguaje que se pued...      2       1  \n",
       "2  es una herramienta de inteligencia artificial ...      2       1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heval.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7463053",
   "metadata": {},
   "source": [
    "Promedio general de puntajes de evaluación humana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80d6a3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bl_gr     3.60\n",
       "bl_coh    2.88\n",
       "fa_gr     2.12\n",
       "fa_coh    1.52\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heval[['bl_gr','bl_coh','fa_gr','fa_coh']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e8898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9441aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
