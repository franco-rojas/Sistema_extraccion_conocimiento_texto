 Las redes neuronales han sido creadas para simular el cerebro humano, la propiedad más importante que tiene es que tienen la capacidad de entender según los datos que se les entreguen y en los últimos años han tenido un gran avance que lo podemos ver en nuestro día a día. Existen numerosos tipos de redes neuronales, entre ellos se encuentran el perceptron simple y el perceptron multicapa. Hola a todos, soy Ligthy González de Aprendida y en el video de hoy te explicaré qué es el perceptron, su funcionamiento y algunos detalles que debes saber. Por lo tanto, empecemos con el video. Comencemos definiendo qué es el perceptron. Un perceptron es un modelo matemático que tiene la estructura y la funcionalidad de una neurona biológica. Es una sección de Machine Learning que se utiliza para entender el concepto de los clasificadores binarios. Forma parte del sistema de redes neuronales, inclusive se puede decir que tanto las redes neuronales como el perceptron se encuentran interconectadas entre sí. El perceptron constituye el fundamento básico de la red neuronal que forma parte de Deep Learning, se considera como bloques de construcción de una sola capa de la red neuronal. Una red neuronal formada por el perceptron puede definirse como un enunciado complejo con una compresión muy profunda de las ecuaciones lógicas. Un enunciado neuronal que sigue al perceptron es verdadero o falso, pero nunca puede ser ambas cosas a la vez. El objetivo del perceptron es identificar las entradas que intervienen en él, hay que identificar si las características son verdaderas o no. Origen del perceptron El perceptron fue inventado por Frank Rosenblatt en 1957 en Nueva York. Este proyecto formó parte de una investigación de 5 años en donde su objetivo era diseñar un cerebro electrónico con la capacidad de analizar y entender patrones. El objetivo con esta investigación era construir un dispositivo que tuviese funciones similares a la de los humanos, como la percepción, la capacidad de entender conceptos, la orientación, entre muchas otras. Sin embargo, para llevar a cabo todas estas operaciones, un sistema informático convencional tendría que almacenar miles o millones de patrones y luego, siempre que fuera necesario, se buscaría este número excesivo de patrones para reconocer un patrón no visto. Lo que era computacionalmente muy caro y no era una forma económica de identificar un patrón u objeto. Para resolver este problema, Frank Rosenblatt propuso un sistema que podría funcionar según los principios del cerebro biológico y reconocer las similitudes entre los patrones utilizando un enfoque probabilístico en lugar del enfoque determinista. El modelo del perceptron cobró vida gracias a la construcción de un hardware personalizado llamado Mark I Perceptron, diseñado principalmente para el reconocimiento de imágenes. Era una caja negra muy parecida a la red neuronal actual, con una capa de entrada, capas ocultas y una capa de salida. Avanzado unas décadas llegamos a 1986 cuando Geoffrey Hinton presentó un nuevo procedimiento llamado retro propagación, el cual se ha convertido en la columna pértebra de la gran mayoría de investigaciones basadas en redes neuronales de la actualidad. Esta técnica funciona minimizando entre los valores reales y los deseados mediante el ajuste de los pesos del modelo de red neuronal. Hace que la red neuronal aprenda o extraiga características y generalice un patrón o secuencia de entradas para hacer predicciones bastante precisas sobre representaciones de datos no vistas. Componentes principales del perceptron El perceptron está formado por varios componentes que te explico a continuación. Entradas Las entradas en el algoritmo del perceptron se entienden como x1, x2, x3, x4 y así sucesivamente. Todas estas entradas denotan los valores del perceptron de características y la ocurrencia total de las características. Pesos Se observan como valores que se planifican a lo largo de la sesión de preparación del perceptron. Los pesos ofrecen un valor preliminar en el inicio del aprendizaje del algoritmo. Con la ocurrencia de cada inexactitud de entrenamiento, los valores de los pesos se actualizan. Estos se representan principalmente como w1, w2, w3, w4 y así sucesivamente. Suma ponderada Es la proliferación de cada valor de entrada o características asociadas con el valor de paso correspondiente. Función de activación Cada función de activación o no lineal toma un único número y realiza una determinada operación matemática fija sobre él. Hay varias funciones de activación que se pueden encontrar en la práctica. Las más comunes son la simmoide o la relu o unidad lineal rectificada. Salida La suma ponderada se pasa a la función de activación y cualquier valor que obtengamos después del cálculo es nuestra salida predicha. Si te interesa profundizar sobre estos temas de Inteligencia Artificial, en nuestro canal de YouTube podrás encontrar bastante contenido relacionado a estos temas. Por lo tanto te recomiendo que los revises y a su vez que te suscribas al canal si aún no lo has hecho. Hablemos ahora del modelo de Persextron de una capa. Un modelo de Persextron de una capa incluye una Red Feed Forward que depende de una función de transferencia de umbral en su modelo. Es el tipo más sencillo de Red Neuronal Artificial que puede analizar solo objetos linealmente separables con resultados binarios, es decir, 1 y 0. Si hablamos del funcionamiento del modelo de Persextron de una capa, su algoritmo no tiene información previa, por lo que inicialmente los pesos se asignan de forma inconstante. Entonces el algoritmo suma todas las entradas ponderadas. Si el valor añadido es más que algún valor predeterminado o valor umbral, entonces el Persextron de una capa se declara activo y entrega la salida como más 1. En palabras sencillas, los valores de entradas que han sido multiplicados entran al modelo de Persextron y estos son los datos que se utiliza para ejecutar el mismo. Una vez que se hayan obtenido los valores de salida se comparan con los valores que se estima se debe obtener. Si no hay diferencia entre ellos podemos decir que nuestro modelo está perfecto y no hay necesidad de modificar los pesos. Si por el contrario, los valores de salida que hemos obtenido con nuestro modelo son diferentes a los valores estimados se deben ajustar los pesos para poder obtener un mejor resultado. Expliquemos ahora el modelo de Persextron multi capa. Un modelo de Persextron multi capa tiene una estructura similar a la de un modelo de Persextron de una sola capa con más número de capas ocultas. También se denomina algoritmo de retro propagación. Se ejecuta en dos etapas, la etapa hacia adelante y la etapa hacia atrás. En la etapa hacia adelante las funciones de activación se originan desde la capa de entrada a la salida y en la capa hacia atrás el error entre el valor observado y el valor demandado se origina hacia atrás en la capa de salida para modificar los pesos. En términos sencillos, el Persextron multi capa está formado por numerosas redes neuronales sobre distintas capas. Acá la función de activación será no lineal, por lo tanto debemos aplicar funciones de activaciones no lineales como la sigmoide, la relu entre muchas otras. Los modelos de Persextron son el tipo más simplista de red neuronal en la que llevan una entrada. El peso de cada entrada toma la suma de la entrada ponderada y se aplica una función de activación. Aceptan y construye solo valores binarios, es decir, el Persextron solo se implementa para la clasificación binaria con la limitación de que solo son aplicables para objetos linealmente separables. El Persextron es la base de las redes neuronales, por lo tanto es muy importante entender cómo funciona el Persextron para poder ir avanzando con redes neuronales mucho más profundas. Te dejo la siguiente pregunta para comprobar lo que has aprendido con este contenido. De las siguientes afirmaciones ¿Cuál crees que es cierta? Opción 1 El Persextron es un modelo matemático inspirado en una estructura y función simplificadas de una única neurona biológica. Opción 2 El Persextron se puede utilizar para proyectos tanto de clasificación como de regresión. Opción 3 Los componentes del Persextron son la entrada, pesos, función de activación, suma ponderada y la salida. Deja en los comentarios cuál crees que es la respuesta correcta, puede ser una o más las respuestas correctas. No te olvides de pasarte por la cajita de información debajo de este video en donde te dejo varios enlaces que seguramente serán de tu interés sobre publicaciones relacionadas a la Inteligencia Artificial y si aún no lo has hecho, suscríbete a nuestro canal y presiona en la campanita de notificación para que estés al tanto de todos los contenidos que vamos publicando. También puedes escribir en los comentarios cualquier duda o sugerencia que tengas y estaré encantada de responderla. Te veo en el siguiente video. Chao.
