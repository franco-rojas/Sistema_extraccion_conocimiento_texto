 Cuando desarrollamos un modelo de Machine Learning es común que nos encontremos con los términos parámetros e hiperparámetros, que aunque tienen nombres similares significan dos cosas totalmente diferentes, así que en este vídeo veremos en detalle el significado de cada uno de estos conceptos que resultan fundamentales en el Machine Learning. Pero antes de comenzar los invito a visitar codificandovids.com, en donde encontrarán la academia online con cursos de inteligencia artificial, ciencia de datos y Machine Learning que les permitirán construir su carrera en estas áreas y todo por una suscripción mensual de tan sólo 10 dólares. Así que listo comencemos. Partamos de un ejemplo hipotético para entender estas diferencias entre parámetros e hiperparámetros y para ello usaremos el mismo ejemplo que analizamos en un vídeo anterior cuando hablamos de las diferencias entre algoritmos y modelos de Machine Learning. Supondremos que una entidad bancaria ha recolectado información de muchos clientes y que usaremos el nivel de endeudamiento y el nivel de ingreso para determinar para cada cliente su perfil que puede ser una de dos categorías, inversionista o consumidor. Los clientes con perfil inversionista serán aquellos con ingresos relativamente altos y niveles de deuda relativamente bajos, mientras que los clientes con un perfil consumidor tendrán niveles intermedios tanto de ingreso como de deuda. Como lo vimos en el vídeo en el que hablamos de la diferencia entre algoritmos y modelos, vimos que una manera de resolver este problema es encontrar una frontera que nos permita separar un tipo de cliente de otro con base en sus niveles de ingreso y de deuda y en este caso la frontera puede ser simplemente una línea recta que deberá tener una orientación adecuada para que la separación sea correcta. Así si tenemos esta recta con la orientación ideal podremos clasificar a un cliente como inversor si sus niveles de ingreso y de deuda hacen que esté de un lado de la recta o como consumidor si dichos niveles hacen que esté del otro lado de la recta y esta línea recta se caracteriza por tener unos coeficientes que determinarán precisamente la orientación de esa recta y la forma de calcular estos coeficientes de manera automática es usando un algoritmo que en primer lugar define una recta con una orientación arbitraria, es decir con unos coeficientes totalmente aleatorios y luego de forma iterativa el algoritmo repite una serie de pasos con el fin de refinar la orientación de esta recta. En cada iteración se toma la recta construida y se generan las predicciones, es decir que se clasifica cada cliente de nuestro set de datos como consumidor o inversor dependiendo de si sus características hacen que esté de uno u otro lado de la recta. Luego se evalúa el error existente entre las predicciones y las categorías reales a las que pertenece cada cliente y finalmente se modifican los coeficientes de la recta dependiendo de la magnitud de este error, buscando que este ajuste permita mejorar progresivamente dichas predicciones. Al final de todo esto lo que buscamos es obtener el error más pequeño posible, es decir que las predicciones se parezcan al máximo a las categorías reales a las que pertenecen los clientes y tras ejecutar el algoritmo obtendremos el modelo, el producto final que nos permitirá predecir idealmente de forma correcta a qué categoría pertenece un cliente dados sus niveles de ingreso y de deuda. Pues resulta que implícitamente en este proceso de construcción del modelo a partir del algoritmo encontramos precisamente los conceptos de parámetro e hiperparámetro, así que entendamos a partir de este sencillo ejemplo cada uno de estos conceptos comenzando con los parámetros. En el ejemplo anterior vimos que la orientación de la recta depende de unos coeficientes que son elegidos inicialmente de forma aleatoria pero que iremos refinando a medida que ejecutamos cada paso del algoritmo una y otra vez hasta llegar a esos valores ideales, pues resulta que estos coeficientes se conocen precisamente con el nombre de parámetros y son variables internas del modelo que se pueden obtener de forma automática a través del algoritmo de entrenamiento. Al decir que estos parámetros se obtienen de forma automática nos estamos refiriendo que se obtienen o se pueden estimar a partir de los datos que en nuestro caso corresponde a la información que ha recolectado el banco de cada uno de los clientes y cuyos valores no podremos controlar directamente en cada iteración del algoritmo de entrenamiento, así que teniendo claro este concepto veamos ahora qué son los hiperparámetros y cómo se diferencian de los parámetros. Volviendo al ejemplo anterior vimos que en el caso del algoritmo los pasos que allí definimos se tienen que repetir un cierto número de veces, este número de repeticiones se conoce como el número de iteraciones y es una cantidad numérica que nosotros debemos definir al momento de programar el algoritmo y que debemos escoger cuidadosamente pues si definimos un número inadecuado de iteraciones no lograremos obtener la frontera de separación ideal al final del entrenamiento, así que podemos definir un hiperparámetro como una variable que es externa al modelo es decir que no se obtiene automáticamente a partir de los datos y que en su lugar debemos definir manualmente al momento de programar el algoritmo de entrenamiento. Bien teniendo estas definiciones de parámetros y hiperparámetros veamos ahora algunos ejemplos que nos permitirán entender de forma clara estos dos conceptos. Por ejemplo cuando tenemos una red neuronal cada neurona contiene unos coeficientes que permiten transformar los datos que estamos procesando, estos coeficientes son precisamente los parámetros del modelo pues se calculan de forma automática a partir de los datos durante el entrenamiento, sin embargo para lograr obtener los parámetros más adecuados debemos definir por ejemplo el número de iteraciones del algoritmo de entrenamiento o el número de capas ocultas de la red neuronal o el número de neuronas por capa, estos son los hiperparámetros del modelo pues se trata de valores que definimos al momento de crear la red neuronal. Las redes transformer que son la base de modelos como VARGT, GPT o ChatGPT son un tipo de red neuronal especializada en el procesamiento de secuencias como lo es por ejemplo el texto, en este caso los parámetros son los coeficientes de cada neurona que hace parte de la red, mientras que los hiperparámetros son por ejemplo el número de bloques atencionales o el tamaño del embedding. Una red convolucional es una arquitectura de deep learning que permite procesar imágenes, en este caso los parámetros son por ejemplo los coeficientes de los filtros encargados de extraer diferentes características de las imágenes, mientras que los hiperparámetros pueden ser el número de filtros, el tamaño de cada filtro o el número de capas convolucionales, además cada una de las redes mencionadas anteriormente es entrenada con un algoritmo de optimización que permite ajustar de forma automática e iterativa los parámetros de cada modelo para progresivamente mejorar las predicciones y usualmente este proceso de optimización se basa en el algoritmo del gradiente descendente o en alguna de sus variantes y en el fondo estos algoritmos contienen algo que se conoce como la tasa de aprendizaje que determina qué tan rápido se actualizan los parámetros del modelo en cada iteración de entrenamiento, pues esta tasa de aprendizaje es también otro ejemplo de hiperparámetro y que usualmente encontraremos en diferentes modelos de machine learning. Muy bien a lo largo de este vídeo hemos podido entender estos conceptos de parámetros e hiperparámetros que resultan fundamentales en el machine learning, en esencia un parámetro es una variable numérica interna del modelo que nosotros no podemos controlar al momento de programar el algoritmo de entrenamiento y que por el contrario se calcula de forma automática a partir de Y por otra parte tenemos los hiperparámetros que también son variables numéricas pero que a diferencia de los parámetros sí podemos controlar al momento de programar el algoritmo y antes de hacer el entrenamiento y dependiendo del valor que escojamos para estos hiperparámetros podremos mejorar o empeorar el desempeño del modelo, de hecho existen técnicas de machine learning enfocadas en la afinación de estos hiperparámetros que lo que buscan es encontrar los valores más adecuados de estas variables para generar las mejores predicciones posibles, pero de este tema hablaremos en detalle en un próximo vídeo. Recuerden que si tienen dudas de lo que acabamos de hablar en este vídeo las pueden dejar abajo en los comentarios y recuerden también que si les gustó el vídeo le pueden dar un pulgar hacia arriba de me gusta y compartirlo con todos sus amigos y conocidos pues ya saben que esto me ayudará a llegar cada vez a más y más personas con este tipo de contenido y si aún no lo han hecho los invito a suscribirse al canal y activar la campanita de notificaciones para que youtube les avise cada vez que suba nuevo contenido al canal. Por ahora esto es todo les envío un saludo y nos vemos en el próximo vídeo.
