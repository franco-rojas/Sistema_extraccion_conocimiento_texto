 En el Machine Learning Operations se busca llevar un modelo de Machine Learning de la etapa de desarrollo a la etapa de producción. En la etapa de desarrollo lo que hacemos es entrenar y validar el modelo para luego llevarlo a la fase de producción donde lo desplegamos y lo ponemos a disposición del usuario final. Y es en esta etapa de despliegue donde pueden surgir inconvenientes que hagan que el modelo no tenga el desempeño esperado. Así que en este video veremos en qué consiste el monitoreo de un modelo de Machine Learning que nos permite observar continuamente el desempeño del modelo determinar por qué puede estar funcionando incorrectamente para luego tomar los correctivos necesarios. Pero antes de comenzar los invito a visitar la Academia Online de Codificando Bits donde por una suscripción mensual de tan solo 10 dólares podrán acceder a cursos que les permitirán construir su carrera en ciencia de datos, Machine Learning e Inteligencia Artificial. Este mes estamos con el curso Introducción a la Ciencia de Datos en donde veremos un panorama general de esta disciplina así como una visión detallada de los conceptos y la ruta de aprendizaje requerida para incursionar en esta disciplina. Muy, pero muy recomendado para todos los que estén interesados en iniciarse en este campo. Y ahora sí, comencemos. En videos anteriores hemos hablado de qué es el Machine Learning Operations y en qué consiste el despliegue de un modelo que permite llevarlo de la etapa de desarrollo a la etapa de producción poniéndolo a disposición de un usuario final. Abajo en la descripción les dejo el enlace a estos dos videos. Pero esto es solo el comienzo de la historia porque el reto es lograr que el modelo siga haciendo buenas predicciones una vez entrenado y también después de haberlo desplegado. Para entender esto consideremos un ejemplo hipotético. Supongamos que desarrollamos un modelo para una tienda por departamentos con el fin de predecir cuántos productos de cada categoría se necesitarán cada semana de manera tal que los administradores de la tienda puedan tener con antelación la cantidad suficiente de productos en inventario. Entrenamos, validamos y desplegamos nuestro modelo y todo funciona a la perfección. Durante los primeros meses de uso del modelo se evidencia un incremento en las ventas pues siempre habrá una cantidad suficiente de productos en inventario para las diferentes categorías. Pero aproximadamente un año después los números comienzan a bajar. La demanda de algunos productos era mayor que la predicha por el modelo y para esas categorías no se tenían suficientes productos en la tienda y en otros casos ocurría lo contrario. Para algunos productos la demanda era menor que la predicha por el modelo así que se tenía un exceso de esos productos en inventario. En últimas este modelo que al comienzo funcionó a la perfección con el tiempo se fue degradando y en lugar de generar ingresos comenzó a generar pérdidas para la tienda. Y esto es precisamente un ejemplo de lo que generalmente sucede en la práctica. Desplegar el modelo no es la última fase del proceso porque a lo largo del tiempo puede comenzar a sufrir una degradación en su desempeño. Así que debemos monitorear continuamente su desempeño para detectar posibles fallos y tomar a tiempo los correctivos que sean necesarios. En esencia existen dos grandes grupos de situaciones que pueden explicar la degradación del desempeño los fallos de software y los fallos del modelo. Los fallos de software se deben, como su nombre lo indica, a elementos del software usado durante el despliegue que no funcionan de forma esperada. Por ejemplo pueden ser debidos a ciertas librerías o paquetes que no fueron instalados correctamente durante el despliegue o también debidos a fallos en la CPU o GPU de los servidores. Pero este tipo de fallos no es el que nos interesa, pues dependen de factores externos y podrían ser resueltos más por un ingeniero de software que por uno de machine learning. Los tipos de fallos que nos interesan son los relacionados directamente con el machine learning, que hacen que el modelo no genere buenas predicciones. Estos fallos son más difíciles de detectar y de manejar que los fallos de software, pero deben ser manejados para que el modelo pueda seguir en la etapa de producción. Los fallos más comunes son los que se conocen como variaciones en la distribución y pueden terminar afectando prácticamente a cualquier modelo de machine learning. Cuando entrenamos el modelo en la etapa de desarrollo, lo hicimos usando un set de entrenamiento y prueba. Idealmente en la etapa de producción los datos usados deberían tener las mismas características usadas en la etapa de desarrollo, pero esto es casi imposible de controlar, lo que hace que estas ligeras diferencias terminen afectando el desempeño del modelo. Entre las variaciones en la distribución más comunes tenemos la deriva de datos y la deriva de concepto. En la deriva de datos hay cambios ligeros o significativos en las características o distribución de los datos de entrada con respecto a los usados durante el entrenamiento. Supongamos que entrenamos un modelo de reconocimiento facial, pero únicamente con imágenes tomadas durante el día. Lo llevamos a producción e inicialmente funciona bastante bien, pero de repente comenzamos a usarlo para detectar rostros en la noche y es acá donde comenzamos a ver una degradación del desempeño. En este caso tenemos precisamente una deriva de datos, pues los datos de entrenamiento provienen de una distribución diferente de la de los datos recibidos por el modelo en producción. Por otra parte la deriva de concepto se da cuando la distribución de los datos de entrada permanece sin variación, pero a pesar de ello las predicciones hechas por el modelo comienzan a cambiar. Por ejemplo, supongamos que desarrollamos un modelo para predecir el precio de un inmueble con base en algunas de sus características como el área, el número de habitaciones y el número de baños. Para un inmueble en particular el modelo predice un costo de $500,000 dólares, pero resulta que tiempo después hubo una crisis inmobiliaria y el modelo, a pesar de usar datos de entrada con la misma distribución usada en el entrenamiento, predice ahora que el costo es de $200,000 dólares. Perfecto, ya tenemos claros los principales factores que pueden degradar el desempeño de un modelo, así que podemos definir el monitoreo como la fase del Machine Learning Operations, en la cual medimos diferentes variables de desempeño del modelo y las comparamos con valores de referencia para determinar si continúa generando predicciones adecuadas o si es necesario tomar acciones que busquen mejorar el desempeño. Y hay varias formas de realizar este monitoreo, algunas bastante simples y otras más sofisticadas. La más sencilla de todas es registrando continuamente una métrica global del desempeño del modelo y comparándola con un nivel de referencia. Por ejemplo, si tenemos un sistema de detección de rostros que en la etapa de desarrollo tenía una exactitud del 97%, entonces podemos registrar periódicamente, por ejemplo a diario, este desempeño en el modelo desplegado y si se observa que cae debajo de este nivel de referencia, se podría generar una alerta indicándonos que debemos tomar alguna acción antes de que las cosas sigan empeorando. El inconveniente de realizar el monitoreo utilizando una métrica de desempeño global es que no nos permite ver las razones de fondo que expliquen esa degradación, es decir, si el problema de fondo es una deriva de datos o una deriva de concepto. Una forma más sofisticada de realizar este monitoreo es, por ejemplo, obtener la distribución estadística de los datos de entrada antes del despliegue y periódicamente calcular esta distribución, pero para los datos usados por el modelo desplegado y luego aplicar una prueba estadística para determinar si existen diferencias significativas entre una y otra. En el caso de encontrar diferencias, podríamos concluir que el origen de la degradación está en la deriva de datos o podemos hacer algo similar, pero para las distribuciones de datos a la salida del modelo antes y después del despliegue. De tal forma que si encontramos diferencias estadísticamente significativas, podemos concluir que la degradación del desempeño se debe en este caso a una deriva de concepto. Muy bien, en este video hemos visto que después del despliegue es muy probable que el desempeño del modelo comience a decaer y esto se debe precisamente a que tanto los datos como el entorno en el cual se encuentra el modelo son dinámicos y pueden comenzar a tener variaciones en el tiempo. Así que el monitoreo permite detectar esta degradación en el desempeño bien sea usando métricas globales o técnicas más sofisticadas como la estimación de las distribuciones y pruebas estadísticas aplicadas a los datos de entrada o de salida del modelo. Pero este proceso no termina en el monitoreo porque si confirmamos que efectivamente hay una degradación del desempeño, tenemos que tomar acciones correctivas para garantizar que el modelo siga estando en la fase de producción. Esta fase correctiva se conoce como el mantenimiento del modelo y de ella hablaremos en un próximo video. Así que por el momento esto es todo, no olviden darle un pulgar hacia arriba de me gusta al video y compartirlo con sus amigos y conocidos, pues ya saben que esto me ayudará a seguir desarrollando este tipo de contenido y a que el canal siga creciendo. Y también los invito a suscribirse al canal si aún no lo han hecho y activar la campanita para recibir las notificaciones cada vez que suba nuevo contenido al canal. Por el momento esto es todo, les envío un saludo y nos vemos en el próximo video.
