 Si eres una persona interesada en la inteligencia artificial o acostumbras a ver mi canal, sabrás que gran parte de la revolución que se ha vivido en los últimos años dentro del deep learning se lo debemos en sus inicios a los avances del campo de la visión por ordenador, y en concreto al desarrollo de un tipo de red neuronal muy importante que está especializada para trabajar con imágenes, las famosísimas redes neuronales convolucionales. La importancia de estas redes viene de su capacidad de poder descifrar los patrones más complejos en enormes datasets de imágenes, dotando de ojos a máquinas que tanto pueden observar rostros de personas como radiografías de pacientes como los peatones que se cruzan ante un coche autónomo. Hemos conseguido que las máquinas puedan percibir el mundo que les rodea. Una tecnología tan importante que, ahora que lo pienso, creo que nunca ha dedicado un vídeo entero a explicar sus fundamentos. A ver, no es cierto esto. En muchas ocasiones en el canal hemos hablado de redes generativas, autoencoders, modelos pics to pics y más cosas, que al final implicitamente están utilizando los principios tras este tipo de redes. Y es por eso que no solamente quiero hablaros de que son las redes neuronales convolucionales, sino que quiero ir más allá y por eso os adelanto de que este vídeo es la primera parte de una trilogía donde no solo vamos a estar viendo los fundamentos detrás de estas redes, sino que también vamos a ver una serie de técnicas de optimización que nos van a permitir entender mejor su funcionamiento. Y no solo eso, sino que os va a encantar, por fin lo sé, va a ver, y a notebooks de toda la teoría. Es decir, vamos a ir programando todos los conceptos que vayamos viendo en esta serie de vídeos. Así que nada, mi consejo es que si no estáis suscritos, os suscribáis, por supuesto. Y si estos vídeos ya están publicados, que echéis un vistazo a la caja de descripción abajo que estarán todos puestos en modo de playlist. Bien, ya estamos todos en el tren del hype. Perfecto, porque antes de empezar quiero hablaros sobre el patrocinador de este vídeo. Se trata de la nueva edición del Master Ejecutivo sobre Inteligencia Artificial en castellano que viene de la mano del IIA, del Instituto de Inteligencia Artificial. Se trata de un máster que está diseñado, está orientado para personas, para profesionales, directivos, inversores que realmente quieran buscar extraer un valor a toda esta tecnología de Inteligencia Artificial que no paramos de ver aquí en el canal y que lo quieran hacer sin cometer los típicos errores que se dan en la industria. No busca ser un máster muy técnico en la parte de matemáticas ni programación, sino que lo que quiere es daros una visión realista de lo que es la Inteligencia Artificial y cómo se puede implementar lejos de sensacionalismos. El poder liderar un proyecto de IA, el poder tomar decisiones estratégicas y el poder ir orientando vuestro perfil profesional hacia una tecnología que todos sabemos que tiene un gran potencial de cambio, pero que no mucha gente sabe llevarlo a la práctica. Además contaréis con una plantilla de profesores que tienen una cosa muy importante y es experiencia real. Destaco el perfil de, por ejemplo, Andrés Torrubia, que si estás metido un poco en el mundo del Machine Learning, os sonará. No sólo por ser una persona que tiene una amplia experiencia dentro de plataformas como Kaggle, sino por también su podcast Software 2.0, donde entrevista a gente muy del ámbito no sólo académico, sino también industrial. Es decir, un perfil de profesores que es todo un lujo. El máster evidentemente, dada la situación actual es 100% online, lo cual es una ventaja para muchos de vosotros y se realizará de enero hasta junio de 2021. Si os interesa, os recomiendo que os matriculeis ya, porque además de que las clases son limitadas, el precio de la matrícula va a estar reducido hasta el 1 de diciembre. Y no sólo eso, sino que también por ser espectadores de Doge.csv, contáis con un código de descuento del 10%. Tenéis toda la información aquí abajo también en la descripción. Así que nada, aprovechad esta oportunidad si queréis mejorar vuestros perfiles profesionales. Echad un ojo a la página web del máster y ahora sí, comenzamos. Para el vídeo de hoy necesitamos entender bien los principios básicos que hay detrás del proceso de visión, no el artificial, sino el humano. Si yo, por ejemplo, te muestro esta imagen de aquí, rápidamente sabría decirme qué es lo que estamos viendo, ¿no? Una cara. Esto es porque tú seguramente has escaneado la imagen y ha detectado la presencia de algunos elementos que tú ya sabes, por tu aprendizaje, que conforman a un rostro. Aquí hay ojos, aquí hay una boca, aquí hay una nariz… genial. Pero ¿por qué sabes que esto es un ojo? Bueno, porque ha detectado una serie de elementos que conforman normalmente a un ojo. Una pupila negra, líneas que son pestañas, superficies blancas… y todo esto también lo has sabido reconocer porque eres capaz de detectar patrones circulares, cambios de contrastes, texturas y así sucesivamente. Al final, si reproducimos los pasos que realiza tu córtex visual, con lo que nos encontraremos es con un procesamiento en cascada, donde primero se identifican aquellos elementos básicos y generales y donde en posteriores capas esto se combina para generar patrones cada vez más complejos. Toda esta neurociencia, que bien explicada podéis encontrar en el libro de mi amigo Ignacio Crespo, fue la fuente de inspiración para investigadores como Jean Lecant, quien en 1989 introdujo el primer diseño de una red neuronal convolucional para la detección de números escritos en cheque pancarios. ¿Y qué es una red neuronal convolucional? Pues un tipo de red neuronal cuyo diseño ha sido pensado para sacar partido a algo muy evidente que encontramos en una imagen, su estructura espacial. Es decir, con una red neuronal típica, clásica, vanilla, la de toda la vida, una red neuronal multicapa, lo que estaríamos haciendo es introducir el valor de cada pixel como si una variable independiente se tratara, como si fuera un vector plano. En ningún momento le estaríamos dando la importancia que tiene su posición dentro de la imagen, significando esto que lo mismo daría a meter imágenes con esta ordenación, que con esta, que con esta otra. La red neuronal multicapa solo vería un vector plano de pixeles, pero no. Nosotros sabemos que en realidad esta independencia de pixeles no es habitual en una imagen. Normalmente el valor de un pixel va a estar muy ligado al de sus pixeles vecinos, tanto en su ancho como en el alto. Y esto es lo que hace que surjan estructuras, formas y patrones que analizadas correctamente nos pueden beneficiar a la hora de entender que estamos viendo. Y con esta idea surgen las redes neuronales convolucionales. Una red neuronal convolucional es un tipo de red neuronal que se caracteriza por aplicar un tipo de capa donde se realiza una operación matemática conocida como convolución. Una convolución aplicada sobre una imagen no es más que una operación que jugando con los valores de los pixeles es capaz de producir una imagen como esta. Ay, perdón. Concretamente cada pixel nuevo que vayamos a generar se calculará colocando una matriz de números que llamaremos filtro o kernel sobre la imagen original y donde multiplicaremos y sumaremos los valores de cada pixel vecino para obtener así el nuevo valor de aquí. Si desplazamos el filtro realizando esta operación por toda nuestra imagen, lo que obtendremos como resultado será esta nueva imagen de aquí. Dependerá por tanto de cómo configuremos los parámetros de nuestro filtro que podremos obtener un resultado u otro. Por ejemplo, un valor central de 1 y el resto de los vecinos a 0 nos hará una copia exacta de la imagen original. Vamos, que no habremos hecho nada. Si por ejemplo multiplicamos por 1 el valor de cada pixel incluyendo a los vecinos y dividimos entre el número total de ellos entre 9, lo que estaremos calculando será la media de los colores de los pixeles. En conjunto nos dará como resultado un desenfoque en la imagen original. Método que se utiliza para implementar los efectos que vemos hoy en día en muchos de los software de edición que utilizamos. Y fíjate bien en esto. Si por ejemplo configuramos los valores del filtro para que estos pixeles de aquí multipliquen en negativo y estos de aquí en positivo, lo que conseguiremos es que cuando el filtro se sitúe en una zona donde los colores son iguales aquí y aquí, ambos términos en positivo y negativo se cancelarán y que para valores contrarios su activación sume más. Escaneando con este filtro toda nuestra imagen, ¿qué sucederá? Es que habremos configurado un filtro que se activará cuando encuentre diferencias de contraste y por tanto que sirva para detectar bordes verticales. ¿Lo ves? Con esto lo que hay que entender es que esta operación de convolución sobre una imagen puede detectar cosas diferentes según cuáles sean los valores del filtro que definamos. ¿Y cuál vamos a definir? Pues no vamos a ser nosotros, sino que estos son los valores que la red neuronal irá aprendiendo poco a poco para poder hacer mejor su tarea. El trabajo de estos filtros para detectar patrones es el principal trabajo de la red neuronal convolucional. A cada una de las imágenes generadas se le conoce como un mapa de características, ya que actúa como un mapa donde se nos indica en qué parte de la imagen se ha detectado la característica buscada por dicho filtro. Cada píxel blanco será una activación que nos indique que el elemento buscado estaba ahí. Por tanto, entra una imagen, aplica una serie de convoluciones y genera un conjunto de mapas de características. ¿Es eso todo? Pues podríamos decir que sí. La cosa es que al final, el potencial de este tipo de redes se encuentra en que esta operación se va a realizar secuencialmente, donde el output de una de las capas se va a convertir en el input de la siguiente. Fíjate por ejemplo cómo si de entrada tenemos una imagen normal a color, con sus tres canales RGB, esto se podría interpretar como que en realidad tenemos tres mapas de características diferentes donde se han detectado elementos en rojo, en verde y en azul. ¿Lo ves? Tenemos tres mapas de características donde si ahora realizamos la operación de convolución con vamos a decir 16 filtros, podremos detectar 16 cosas diferentes que notarán como resultado 16 mapas de características. 16 imágenes que ahora pasarán a ser el input de la siguiente capa convolucional. Pregunta. Perfecto, sí, ok. Podemos utilizar filtros de tamaño 3x3 o 7x7 píxeles para ir escaneando poco a poco nuestra imagen a la búsqueda de patrones. ¿Pero es esto suficiente? ¿Es posible que un filtro tan pequeño pueda detectar patrones tan complejos como por ejemplo un ojo, la rueda de un coche o el comportamiento errático ante el miedo al fracaso de una persona que vive en una sociedad que ni se plantea ni busca un objetivo común a seguir? ¿Es posible que un filtro detecte todo esto? No lo sé, dímelo tú. Ah, has preguntado. Vale, te respondo yo. La respuesta la encontramos en la sucesión de capas, en el deep del deep learning, en la profundidad de la arquitectura de nuestra red. Lo que sucede es que la operación de convolución cada vez se va a ir haciendo más potente. Fíjate, ahora donde antes teníamos una región de 9 píxeles, nuestro filtro lo ha convertido en un único píxel de información. Y por tanto, si volvemos a aplicar ahora una convolución sobre estos mapas de características, en realidad estaremos accediendo a cada vez más información espacial de la imagen original. Esto es algo que además podemos incentivar reduciendo cada cierto tiempo la resolución de nuestros mapas de características. Ya Carlos, pero es que al final te estás flipando mucho con esto de las convoluciones ya que no dejan de ser unas operaciones que sí, que te pueden detectar cambios de contraste, de texturas, superficies planas, pero tampoco pueden hacer mucho más, ¿verdad? Pues sí y no. A ver, sí es cierto que solamente pueden hacer eso, pero piensa que aquí estamos haciendo detecciones sobre las detecciones recibidas de las capas anteriores. Es decir, al final la operación de convolución por sí sola tampoco puede detectar cosas muy complejas más que bordes y patrones muy simples. Pero volver a hacer estas detecciones sobre las detecciones anteriores nos permite componer cada vez patrones más complejos. Por ejemplo, imagínate un filtro que pudiera detectar la presencia de un elemento en la región de los píxeles vecinos en estas cuatro esquinas. Un filtro como este. No parece gran cosa, ¿verdad? Pero imagínate que esto se aplicara ahora sobre los mapas de características de haber detectado en las capas anteriores bordes con diferentes inclinaciones como estas. Esto, si lo componemos, podría darnos como resultado una forma geométrica sencilla parecida a un rombo. Y esto, a lo mejor sumado con el resultado de otro mapa de características así, nos podría empezar a generar un patrón sencillo de un ojo. Es por eso que el diseño de una arquitectura convolucional normalmente se representa en artículos y papers como una especie de embudo donde la imagen inicial se va comprimiendo espacialmente, es decir, su resolución va disminuyendo, al mismo tiempo que su grosor va aumentando. Es decir, el número de mapas de características que vamos detectando va en aumento. ¿Y dónde acaba todo esto? Pues bueno, cuando tu imagen ya pasa por todo el embudo convolucional, ya llegaremos a un punto donde habremos detectado todos los patrones necesarios. Contaremos con muchos mapas de características que ahora sí podemos meter como input independientes dentro de una red neuronal multicapa que acabará por tomar la decisión de qué es lo que hay en esa imagen. Y esto ahora sí son los fundamentos de una red neuronal convolucional. Un tipo de arquitectura de diseño elegante y que realmente si os fijáis cuenta con una serie de operaciones que son bastante sencillas y donde el único aprendizaje, el único entrenamiento que se realiza es el de aprender los filtros. Es súper interesante ver cómo la red aprende automáticamente esta idea jerárquica donde Los primeros filtros son filtros muy básicos y donde luego por composición se van encontrando filtros cada vez más abstractos. Una arquitectura cuyo diseño ha estado presente en toda la revolución que hemos vivido en el campo del deep learning y que nos ha permitido contar con todos los avances que disfrutamos hoy en día. Quedan una serie de preguntas. Cómo podemos estar tan seguros de esto? Cómo sabemos realmente que la red está aprendiendo jerárquicamente? Cómo sabemos qué patrones está aprendiendo? Acaso es posible abrirla y poder acceder a sus entrañas? La respuesta es que sí. Y el cómo lo sabréis en el próximo vídeo. Por fin tengo ya el vídeo de redes neuronales convolucionales. Era un vídeo que llevaba mucho tiempo queriendo hacer porque es algo fundamental en todo lo que vamos viendo en el canal y espero que os haya servido, que os haya servido para entenderlo mejor, para aprender si no lo conocíais, para que lo tengáis como recurso para ponerlo en clase. Y en cualquier caso, si tiene un valor para vosotros, recordaros que está disponible el patrón del canal para que apoyéis todo el trabajo que desinteresadamente hago aquí en el canal para todos vosotros, para que tengáis toda esta información gratis en YouTube. También os recuerdo que tenéis abajo en la descripción toda la información del máster que os he comentado al principio por si queréis echarle un vistazo y nada más. Nos vemos con más inteligencia artificial en el próximo vídeo.
