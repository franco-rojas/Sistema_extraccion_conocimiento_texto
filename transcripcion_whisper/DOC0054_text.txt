 Este vídeo está patrocinado por la Universitat Politécnica de València. Llevo unas cuantas semanas con una idea en la cabeza y es que creo que el campo de la inteligencia artificial se está acelerando, que las cosas están yendo bastante más rápido de lo que pensábamos y que el deep learning ha tomado un camino muy prometedor con esta línea de modelos generalistas que son capaces de hacer un montón de cosas que creo que en los próximos años nos van a traer un montón de sorpresas y aplicaciones increíbles. En ese sentido GATO, uno de los últimos trabajos del laboratorio DeepMind, viene a hacer una buena demostración de ello y es que GATO consigue hacer lo que ya hacía DQN o Mew0 en trabajos anteriores, aprender a jugar con un rendimiento superior al del humano a diferentes juegos de la consola Atari. Pero también GATO va a poder generar texto realista como haz un modelo tipo GPT-3 y va a permitirte poder chatear con él o hacer descripciones de una imagen dada como input. Pero no solo eso y es que GATO también puede aprender a generar los movimientos que tiene que realizar un brazo robótico real para resolver por ejemplo la tarea de apilar cubos. Una misma red entrenada, GATO, puede aprender a hacer todo esto. Y esto es importante porque mira, cuando hace un par de años DeepMind presentó el sistema Mew0 que era capaz de adaptarse a diferentes juegos de Atari y aprender a jugar muy bien a ellos, pues lo sorprendente de aquel sistema era que realmente habían diseñado una arquitectura de Deep Learning que era capaz de adaptarse a diferentes tipos de problemas. Tú tenías que entrenarla para cada juego y ésta pues te daba un muy buen rendimiento jugando a ellos. Mola. Pero de lo que estamos hablando hoy es algo mucho más impresionante porque sí, estamos hablando de una misma arquitectura pero entrenada una única vez. Entrenada para poder adaptarse a cada uno de estos juegos y no solo eso sino todas las otras tareas que hemos descrito anteriormente. Sí, aprender a jugar a juegos pero también a chatear, a describirte imágenes, a mover brazos robóticos. Una misma red neuronal entrenada para gobernarlas a todas las tareas. Este trabajo va en la línea de lo que ha demostrado modelos como GPT-3 en el campo del procesamiento del lenguaje natural. ¿Por qué diseñar y entrenar a un montón de modelos independientes para que hagan tareas muy concretas? Como por ejemplo aprender a resumir un párrafo de un texto o aprender a traducir del español al inglés. Si en realidad lo que podemos hacer es coger a uno de estos modelos, escalarlo a lo bestia, darle un montón de datos y entrenarlo para una tarea mucho más genérica como aprender el lenguaje. Cuando a GPT-3 se le entrena para aprender a predecir cuál es el siguiente token, cuál es la siguiente palabra dada una secuencia anterior pues aprende muy bien su tarea. ¿Puede autocompletar texto? Sí. Pero es que además esta tarea de autocompletar es lo suficientemente versátil para que el modelo pueda realizar otras tantas tareas para las que nunca fue entrenado. Y es que al final esta tarea de autocompletar texto es lo suficientemente versátil para poder adaptarla a otro tipo de tareas. Por ejemplo, para un texto muy largo yo podría escribir en una frase un resumen de este texto sería y darle autocompletar. Y GPT-3 me haría un resumen. Pues esta misma idea es la que GATO quiere explorar, pero en este caso ampliando el abanico de tareas que este sistema puede resolver. Y es que el truco es el siguiente, mira. Cuando digo que esto está muy inspirado en cómo funcionan los enormes modelos del lenguaje basados en transformers que aprenden muy bien a modelizar secuencias de datos es porque aquí la arquitectura de GATO es eso, un transformer. En este caso un transformer de 1200 millones de parámetros. Algo que no es tan grande a lo que ya estamos acostumbrados últimamente. Y es que su tamaño sería semejante a lo que sería un modelo GPT-2. Claro, la cosa es, si al final aquí el transformer lo que hace es modelizar muy bien secuencias de token, como por ejemplo texto, ¿cómo podemos adaptarlo a este problema que tenemos, donde tenemos un montón de fuentes de datos diferentes? Pues no pasa nada, si Mao manova la montaña, la montaña se descompone y se convierte en secuencias de tokens. Por ejemplo, texto, ya sabemos que esto es fácilmente convertible a una secuencia de vectores. Imágenes, no pasa nada, las descomponemos en parches de 16x16 píxeles y las suministramos como secuencias. Y por ejemplo para los juegos de Atari, pues tampoco pasa nada, las acciones que el usuario hace en el mando también se van a registrar como una secuencia de botones pulsados. O si queremos enseñar a un brazo robótico a moverse, pues los ejes de giro del brazo robótico serán dados como una secuencia de entrada. Todos los datos de distinta naturaleza adaptados a las necesidades del transformer. Y así funcionaría Gato. Por ejemplo, en el caso del juego de Atari, pues los datos que tenemos son, por un lado, la observación de la pantalla, el estado del juego, y por otro lado, las acciones que hacen que el juego evolucione, los botones que pulsas con el controlador. Pues lo que hace Gato es tomar como input esta secuencia de acciones y observaciones de la pantalla, codificadas como hemos visto, y de esta secuencia aprenderá a hacer predicciones de cuál es la siguiente acción que el jugador tendría que ejecutar. Esta acción será llevada al entorno de simulación donde se ejecute el juego, lo que generará nuevas observaciones que volveremos a codificar para así poder repetir el proceso generando más y más acciones. Así con estas estrategias como Gato puede adaptarse al contexto de los juegos de Atari, pudiendo aprender estrategias que, como digo, le da un rendimiento superior al del humano. Pero claro, es que la misma red entrenada también es capaz de generar texto, también es capaz de generar movimientos de brazos robóticos, también es capaz de describirte imágenes... Es una locura. Esto es lo interesante de este trabajo, y es que entra de lleno en una de las tendencias más interesantes dentro del campo del deep learning de los últimos años. La multimodalidad. El dejar que las redes neuronales puedan aprender de un montón de datos de diferente naturaleza, imágenes, texto, audio, y que con esto está demostrado pues puedan tener un aprendizaje mucho más rico de la información que le estamos suministrando. Por ejemplo, en 2021, cuando nuestros sistemas de visión por ordenador dejamos de entrenarlos únicamente con imágenes, empezamos a integrar también información de lenguaje natural, pues esto funcionaba mejor. Ahora lo que está haciendo DeepMind es ampliar la fuente de datos y el número de tareas a resolver, dejando que un sistema lo pueda aprender todo. ¿Y no se parece esta idea de multimodalidad y aprendizaje multitarea a cómo funciona nuestro cerebro? Este trabajo es interesante no por lo que pueda ser ahora mismo. Pues el sistema a veces funciona muy bien, a veces funciona bien, a veces regular y a veces mal. Como por ejemplo en la generación de chats o descripción de imágenes. Preguntamos, explícame los principios de los agujeros negros. Y Gato responde, creo que estás intentando que te responda una pregunta sencilla, ¿qué es un agujero negro? Sí, efectivamente comienza. Bueno, pues los agujeros negros usualmente ocurren cuando una estrella muere e implosiona y hay una reacción en cadena. Esto típicamente causado por la expansión de los núcleos de helio, vale, bueno, no está mal. O por ejemplo, ¿cuál es la capital de Francia? Marsella. ¿Por qué es Marsella famosa? Por la música jazz. Ok, se inventa los hechos en esta conversación, algo que también le suele pasar a GPT-3. ¿Cuál es la capital de Francia? París. Bueno, en este caso dicen que el rendimiento es muy malo. La verdad que estas conversaciones son bastante decentes, mejores incluso que GPT-2, que era un modelo incluso de mayor tamaño que Gato. Pero bueno, es cierto que estas son conversaciones que ellos han seleccionado específicamente por el buen rendimiento del sistema. Por lo general suelen ser muy superficiales y en muchas ocasiones con datos que son erróneos. Algo similar sucede también con la descripción de imágenes. Podemos ver aquí, en este caso sí seleccionadas aleatoriamente, pues que son descripciones relativamente buenas. Pero que en algunas ocasiones se equivocan. Un hombre con barba que mantiene un plato de comida, bueno, más o menos. Un grupo de personas junto a un caballo, más o menos los conceptos están. Un par de personas que están en el océano, bueno esto sería equivocado, pero vemos que las siguientes descripciones si serían correctas. Un surfero que está tomando una ola en el océano. Un jugador de béisbol que está golpeando una bola. La verdad que es impresionante que el mismo sistema que ha aprendido a jugar los juegos de Atari, repito, también sea capaz de hacer esto. Es algo que en mi cabeza estoy todavía intentando encajarlo. Pero claro, ¿funciona? Pues sí, pero no es tan impresionante si lo empezamos a analizar para cada una de las tareas en específico. Contamos a día de hoy con sistemas de deep learning mucho más potentes que consiguen rendimientos superiores para muchas de estas tareas que estamos viendo. Pero es que la cosa es que Gato no tiene por qué sobresalir en todas estas tareas. No está diseñado con ese plan. La idea tras este modelo, como he dicho antes, es similar a la de GPT-3. Vamos a entrenar a un gran modelo con una tarea lo suficientemente genérica como para poder adaptarla a otras múltiples tareas. Y en este caso el rendimiento que pueda tener no nos va a importar tanto. Porque la cosa tras estos modelos y donde reside su enorme potencial, es en que nos va a servir de base para luego nosotros poder reentrenarlos a la tarea que queramos. Eso sí, utilizando una menor cantidad de datos. Muchísimos menos datos de lo que necesitaríamos si lo fuéramos a entrenar de cero. Y otra cosa más, lo que estamos viendo hoy es el primer paso de lo que está por venir. Porque al final este modelo no deja de ser semejante en tamaño a un modelo tipo GPT-2. Pero que no nos tiene que haber duda de que en futuros años veremos versiones mucho más grandes y potentes de este sistema. Si Gato todavía no ha evolucionado a Tigres, en parte por la motivación de aplicar este proyecto a la robótica real. Si el modelo fuera mayor, los tiempos de inferencia aumentarían. Y esto con la capacidad de computo que tenemos a día de hoy sería inviable para poder ejecutarlo en tiempo real. Y aquí nos encontramos en 2022. La verdad que es increíble lo rápido que está avanzando el campo de la inteligencia artificial. Yo llevo unas semanas desde la salida de Dali2, que viendo todos los avances que están surgiendo, pues Dali2, Palm, Flamingo y un montón de cosas que quiero traeros aquí al canal y que quiero contaros y explicaros. Porque es verdaderamente impresionante. Pues creo que he visto actualizado mi perspectiva respecto a lo que la inteligencia artificial podrá conseguir en los próximos años. No sé si realmente estoy deslumbrado por lo que Dali2 nos ha mostrado. O si es que realmente estoy empezando a entender los cambios de paradigma que están ocurriendo en el mundo del deep learning. Y también el potencial que se esconden tras nuevos modelos que están surgiendo. Pero de verdad creo que estamos en un camino mucho más interesante de lo que estábamos hace un año. Pensad que, bueno, si visitáis vídeos de 2019, 2020, cuando yo hablaba de redes como la de AlphaStar, que conseguía jugar al StarCraft de forma súper eficiente. Fijaos que esos modelos eran modelos que tenían una gran complejidad. Tenían un montón de módulos de procesamiento para procesar cada uno de los tipos de información que se integraban en aquel sistema. Y al final todo aquello era para resolver una única tarea, que era jugar muy bien al StarCraft. Es decir, para resolver una única tarea compleja necesitábamos de un montón de sistemas y módulos de procesamiento diferentes. Y ahora quiero que lo comparemos con lo que tenemos hoy en 2022. Que para resolver una gran variedad de tareas que son complejas en sí misma, ahora el único cerebro que estamos entrenando es esto de aquí. La versatilidad de estas propuestas me hacen pensar que en un futuro cercano nos será extraño tener robots físicos reales con los que podamos verdaderamente interactuar y que podamos entrevistarles y preguntarles sobre oye, ¿qué estás viendo? ¿Qué estás observando a través de tus sensores, de tus cámaras? ¿Cómo estás moviendo tus articulaciones? ¿Cómo te estás desenvolviendo en el mundo que te rodea? ¿Cuál ha sido la estrategia inteligente que has desarrollado para resolver inteligentemente esta tarea que yo te he asignado? Esto es fascinante. Lo repito, estáis tratando con una versión de 2CV que ahora mismo está muy hypeado y que tiene las expectativas muy por las nubes. Así que tomadlo como tal. Pero quiero decir que si hace un año o dos años me hubieras preguntado si algún día llegaríamos a alcanzar este concepto de la Inteligencia Artificial General, la AGI, yo te hubiera dicho que no, que seguramente eso era un concepto muy alejado de lo que estamos haciendo a día de hoy. Una ciencia ficción, una quimera del campo del deep learning que no llegaríamos a alcanzar. Y hoy lo que te diría es que a la vista de los resultados que se van obteniendo y teniendo en cuenta que todavía quedan muchos obstáculos por resolver y que todavía el objetivo está muy lejos, creo que hemos encontrado el camino correcto para movernos en la dirección adecuada. Y mi sensación es que este camino que estamos recorriendo, que dio comienzo hace 10 años con la revolución del deep learning y las redes neuronales, pues creo que está entrando en una nueva etapa. Llamémosle deep learning 2.0 como sea, pero es una etapa donde conceptos como los modelos base o la multimodalidad o nuevos modelos que están surgiendo, pues nos están redefiniendo las expectativas que podemos tener sobre lo que la Inteligencia Artificial será capaz en los próximos años. Creo que nos aproximamos hacia una década que es fascinante. Y ya sea si estoy equivocado completamente porque hoy estoy hypeado hasta las nubes o si verdaderamente tengo razón, en los próximos vídeos que están por venir al canal quiero explicaros cómo funcionan todos estos factores que creo que están redefiniendo lo que es el campo del deep learning. Si os gusta este contenido, mis recomendaciones es que os suscribáis al canal y activéis las notificaciones para recibir siempre alertas cuando suba vídeo. Y si queréis apoyarlo pues ya sabéis que lo podéis hacer siempre a través de Patreon. Si queréis apoyar la divulgación en el campo de Inteligencia Artificial, si queréis apoyar toda esta revolución y que todo el mundo lo pueda conocer y vosotros seguir aprendiendo de todo esto, pues la mejor forma de hacerlo es a través de Patreon y os dejo abajo un enlace para que podáis echarle un vistazo y hacer vuestra aportación. Chicos, chicas, muchas gracias como siempre y nos vemos en el próximo vídeo. Como siempre, el futuro que está por llegar lo conocerás antes aquí en DotsCSUV.
