 Muy buenas a todos, bienvenidos a un nuevo curso de Open Webinas. Mi nombre es Sergio Lozada y vamos a explicar en qué consiste y qué es ELEKKA. ELEKKA es un stack compuesto por tres pilares fundamentales que son el actiSYL, loctas y kibana. Podemos resumirlo como que sería un stack de datos que tiene un almacenamiento distribuido en el actiSYL que sería la base de datos, procesamos la información con loctas antes de almacenarla, vemos las visualizaciones y los dashboard en kibana y podemos realizar consultas sobre dicha información en tiempo real. Pero antes de seguir, ¿qué problemas son los que intenta resolver loctas? El primer problema es la falta de consistencia. ¿Qué consiste la falta de consistencia? Tenemos muchos dispositivos con lox. Dentro de nuestros servidores, por ejemplo, tenemos distintos servicios funcionando y ahora cada servicio tiene un tipo de lox distinto. Entonces, llegan los administradores del sistema y los DevOps geníicamente o administradores web o desarrolladores que necesitan acceder a dichos lox para comprobarlo. Entonces hay gran dificultad ya que los formatos varían y es difícil de entender. Por ejemplo, podemos poner aquí un ejemplo de un lox, otro lox distinto, otro lox distinto, si os fijáis son completamente distinto, ¿vale? Dependiendo del servicio. Incluso hay lox que a lo mejor falla o faltan campos. Entonces, siguiente problema que nos podemos encontrar, el formato de tiempo. De cada lox puede venir con un formato de tiempo distinto. Pues en este viene la fecha, otro como time stamp, otro con la hora al finalizar. Decentralizado, ¿vale? Imaginarse que tenemos que administrar 50 servidores, los lox se encontrarían repartidos en todos esos servidores y cada servidor puede tener un tipo de lox. Entonces, haciendo cuenta dentro de un servidor puede haber diferentes rutas donde encontrar los lox. Un administrador del sistema puede, si tiene dos o tres servidores que administrar, puede acceder por ellos por SSH, hacer un cap de los lox, un grep para buscar algún error, pero si tienes 50 o 100 servidores, la verdad que el SSH y un grep ya no es escalable, ya no puede seguir. Y el último problema puede ser quizás la falta de conocimiento que no se implementan bien las políticas. Como por ejemplo, las personas que tienen que acceder a un lox no tienen permiso. Un lox se encuentra dentro de un servidor, una persona trabaja con un servicio en concreto, tiene que haber que le pasar el servicio, pero resulta que por políticas de empresas no se le permite acceder a dicha máquina. Puede ser uno de los casos. No tienen experiencia para entender una línea de lox. Todos sabemos que las líneas de lox, pues la verdad que hay los mejores lox que tienen 10 campos, pero hay otros que tienen 40. Entonces, cuando ves tal cantidad de información es complicado muchas veces saber este número que representa o esta cadena de texto que es lo que estás representando. Y también se desconoce dónde se encuentra dicha lox. Con servicios que los mejores usuarios finales que utilizan servicios pero que no han trabajado nunca con dichos lox, entran a la máquina, no saben dónde se encuentran los lox, cómo se actualizan, cómo se van repartiendo si se van borrando cada día. Entonces hay como una falta de conocimiento. ¿Qué busca realmente el acte civil? Pues coger toda esta información, procesarla, almacenarla de forma distribuida para poder escalar en Big Data y poder obtener buenos rendimientos con grandes cantidades de información y transformarlo en esto, en visualizaciones. Tener visualizaciones con las que nosotros podemos identificar anomalías, comportamientos, eventos, picos y de forma gráfica y visual. Es decir, lo que nosotros vamos a ver en esta diapositiva, en estas visualizaciones y dashboard no es muy complicado de ver en lo que sería un lox. Entonces, en modo resumen, ¿qué es lo que está realizando Eleka? Recoliza lox de eventos, de aplicaciones, procesa dicha información y la pone a disposición de las personas que lo necesitan, tiene módulos de seguridad, aunque va por SPAC, que ahora mismo es de pago, pero se puede hacer una especie de seguridad adelante y implementar para que cada usuario pueda acceder a la información que realmente solo pueda administrar, que no se cruce, que un usuario no acceda a información la cual no le pertenece. Formateamos los campos. Hemos visto que hay lox que siguen un formato, un RFC, un SysLog, pero puede haber lox que tengan un formato irregular, ya sea de aplicaciones nuestras propias o de algún servicio que no siga ningún formato, como puede ser un SysLog. Entonces, dichos lox son prácticamente una cadena de texto, una cadena de texto que es muy complicada de entender. Entonces, con loxTasks, que es la parte de preprocesamiento que veremos a continuación, nosotros trabajaremos dichos lox y en vez de tener una cadena de texto lo que tendremos son distintos campos, campos que después podremos utilizar para el tema de filtrado. Y presentamos dicha información en dichos campos después en visualizaciones, ¿vale? Es donde podremos realizar búsquedas, donde podemos realizar filtrados, agregaciones y ver la información mucho mejor que en un fichero de texto en módulos. ¿Qué componentes son los que forman el LK? Bueno, pues el primero de ellos sería el HTC, es una base de datos distribuida, distribuye la información entre todos los nodos, por tanto es tolerante a fallos y tiene alta disponibilidad. Al igual que distribuye la información, distribuye Cuando se realiza una consulta o una búsqueda y la información esa se encuentra distribuida, será cada nodo el que procesa dicha información y devuelva los resultados, más o menos por tanto podrá obtener mejor rendimiento. LoxTasks es esa parte de preprocesamiento antes de guardar la información en el HTC que hemos comentado, donde nosotros recojaremos un input, una entrada, trabajaremos los eventos y los sacaremos por una salida, antes de almacenarlo en las bases de datos. Y por último, Kibana es el más visual, es donde nosotros vamos a generar la visualización sobre la información, donde vamos a generar los dashboards. Bien, no solo son estos tres, es decir, esos tres son los pilares, pero no son los únicos módulos que tienen. Alrededor aparece DITS, que son una especie de shipper, una especie de recolector de información, que recogen información, pues ya sea de un fichero, log de unos datos, de eventos, métricas del sistema, como puede ser CPU, como puede ser RAM, hacen comprobaciones de qué servicios se encuentran activos, analizan a nivel de red los paquetes, ven el tiempo de respuesta entre ellos. Y Expac, que sería el módulo de pago, que ofrece algunos plugin extra, como puede ser el sistema de seguridad, monitorización de todo nuestro sistema, alerta, de uso de grafos para ver la relación entre los distintos nodos y los distintos vértices de nuestros datos. Y desde hace unas semanas, machine learning, que sería una forma de aprender no controlada. La propia máquina iría aprendiendo, basado en tiempo, unos comportamientos de red, por ejemplo, pues que por la mañana hay tal cantidad de tráfico en una empresa, en tal oficina y por la noche te cae, y él solo es capaz de aprender dicho comportamiento durante unas semanas y después todo lo que se sale de ese comportamiento te avisaría. Por último, a modo resumen, tenemos todas nuestras fuentes, esas fuentes envía información a Loctas, el cual tiene muchos plugins, tanto de entrada como de salida, entonces podemos meter gran cantidad de datos en Loctas, Loctas procesará dicha información antes de que se almacene la base de datos de las tesis y con Kibana montaremos visualizaciones que accedan a esa información y nosotros poder estamos utilizando. Y esto es un pequeño resumen de qué consiste Loctas.
