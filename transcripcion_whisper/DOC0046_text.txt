 Ya es una realidad, GPT-3 está disponible para todo el mundo. Sí, para todo el mundo, incluso para ti. Si quieres puedes empezar a utilizar hoy esta increíble inteligencia artificial. Para quien no lo recuerde, cuando hablamos de GPT-3 estamos hablando de un enorme modelo del lenguaje, una inteligencia artificial que está entrenada para que, bueno, pues para una secuencia de texto que el usuario puede suministrar, ésta aprenda a predecir cómo tiene que seguir completándolo. Este sistema se hizo muy popular en 2020 cuando OpenAI, la empresa que está detrás de esto, pues publicó sus resultados y bueno, pudimos ver que este enorme modelo, esta enorme red neuronal, pues por primera vez estaba demostrando un rendimiento superior, algo nunca visto antes, a la hora de generar lenguaje natural, el lenguaje con el que tú y yo nos comunicamos. Aquí en el canal y en internet habréis podido ver un montón de ejemplos de cómo se puede utilizar GPT-3, por ejemplo, para generar textos, para generar conversaciones realistas entre diferentes personajes que podemos especificar, para escribir artículos periodísticos, para redactar poesía e incluso para resolver un montón de tareas para la cual esta inteligencia artificial de partida no estaba entrenada. GPT-3 fue impresionante y desde el minuto cero esto ha sido una tecnología que ha estado, bueno, pues cerrada al público general puesto que solamente se podía acceder a través de una API privada. Pero ahora esto se ha acabado y es que OpenAI ya por fin, en un tweet que publicó esta semana, pues ha confirmado que el acceso a la API ya está disponible para todo el mundo. Ya cualquier persona se puede loguear a través de la página de OpenAI y puede acceder a los diferentes servicios que ofrecen a través de su API que podéis utilizar para vuestros proyectos o para directamente investigar cómo funciona esta inteligencia artificial. Sinceramente creo que estamos en un punto de inflexión muy interesante y es que abrir el acceso a esta tecnología va a permitir que mucha más gente pueda estar en contacto por primera vez con un modelo tan potente como este, que tiene sus claros y sus oscuros, que funciona muy bien a veces, pero también en otras ocasiones funciona muy mal. Hoy os voy a contar una serie de trucos, consejos e informaciones que creo que tenéis que manejar antes de empezar a trabajar con esta API. Quiero que este vídeo sirva para que si conoceis gente que le pueda interesar esta tecnología, pues lo compartáis y así todos empezar a marcar un poco este punto de inflexión que representa que una tecnología como esta esté tan disponible ahora para el público. ¿Cómo empezamos con esto? Pues como digo el acceso a GPT-3 es bastante sencillo, simplemente tenéis que loguearos en la web de OpenAI, completar una serie de datos personales. Por algún motivo creo que nos están dando acceso a ciertos países como Perú, no sé exactamente por qué, pero me imagino que no costará mucho sortear este tipo de barreras geográficas que a veces se colocan en este tipo de herramientas. Luego tendréis que seleccionar cuál es el motivo por el cual queréis utilizar esta API, parece que dependiendo del motivo que elijas podrás tener más acceso o menos acceso a las herramientas, pero algunos de ellos implica tener que comunicarte con el equipo e informarles de para qué vas a utilizar la API. Así que aquí cada uno elegir la propuesta que mejor os convenga. Y a partir de este momento se te abren las puertas. Tienes acceso a GPT-3. En este punto la forma más rápida de empezar a jugar con GPT-3 es a través del Playground. El Playground es este entorno que habréis visto muchas veces en mi canal de YouTube donde yo he interactuado con el sistema y es básicamente esta ventana que tenemos aquí donde podéis escribir cualquier texto como input, darle a control enter y que GPT-3 continúe con la generación. Por ejemplo, GPT-3 es un enorme modelo de lenguaje capaz de simular el lenguaje natural, ha sido desarrollado por OpenAI y cuenta con una enorme base de datos de más de 19 millones de entradas que se encuentra dentro de un repositorio público. Con esto hay muchas cosas que comentar sobre el funcionamiento de GPT-3. Quien haya visto los vídeos previos que he ido publicando en el canal durante el último año sabrá que este sistema no se tiene que basar en una realidad que sea rigurosa, sino que en este caso lo que va a hacer es crearte un texto que en la forma, no en el fondo, pues parezca coherente. Tú esto se lo puedes leer a cualquier persona y ella dirá vale, tiene sentido, pero tiene sentido desde un punto de vista de la forma, no del fondo. GPT-3 no tiene por qué darte datos correctos y esto es muy importante tenerlo en cuenta. Otro detalle interesante es que fijaos que yo me estoy comunicando con GPT-3 en español. Esto es un modelo de lenguaje que principalmente está entrenado con texto en inglés, pero eso no nos impide poder comunicarnos con él en español. Todavía no se tiene muy claro si el rendimiento de GPT-3 es mejor o peor en inglés que en español o en español que en inglés o si realmente su capacidad de generar lenguaje trasciende al propio idioma y luego puede comunicarse traduciendo, por ejemplo, del inglés que sería su lenguaje nativo al español y con esto podría generar un texto que fuera realmente bueno incluso en otros idiomas. Pero ya útil, podéis utilizarlo en español si así queréis y por lo general para mí los resultados que me ha proporcionado son bastante buenos incluso trabajando con mi propio idioma. Y aquí hay otro detalle, GPT-3 es muy bueno adaptándose al input que le hayas dado. Si el texto que le has proporcionado es rico en detalles, con frases complejas y bien construidas, el texto que te va a generar GPT-3 por lo general será un texto rico en detalle, con frases más complejas y bien construidas. Si por el contrario tu input se basa en un texto, en una conversación más simple y con poca profundidad, pues GPT-3 se va a comunicar así. Así que en muchas ocasiones si el resultado que obtienes no es tan bueno, pues preocupate en ver si el input que le estás proporcionando realmente se asemeja a lo que quieres que genere. Una conversación de ascensor como esta te va a generar una conversación de más... Wow, no me esperaba esta respuesta. Porque ya tenemos aquí a GPT-3 que es un robot que habla nuestra lengua, que tiene una inteligencia artificial que habla nuestro idioma y que además ha venido desde España, desde Barcelona. Bueno, no me esperaba este tipo de respuesta, ¿vale? Pero por lo general suelen ser... Vale, oh mira, GPT-4. Bueno, lo que está claro es que os lo vais a pasar bastante bien con esto. Si por el contrario le planteáis una conversación un poquito más desarrollada, pues ahí podemos obtener respuestas también más interesantes. Desde luego la definición de la inteligencia artificial es un tema amplio y complejo. Podríamos decir que la inteligencia artificial es el conjunto de sistemas de orden superior y resolver problemas, bla bla bla. ¿Veis la diferencia? El input, el contexto en este caso es fundamental. Si nos fijamos en la derecha tenemos un menú donde podemos configurar además el comportamiento que queremos que tenga GPT-3. Tenemos parámetros como la temperatura que nos permitiría, por ejemplo, pues tener respuestas más originales y creativas, un poco fuera de la distribución normal de respuestas que podría dar este sistema o la longitud de las respuestas, cuántos tokens queremos que se generen o otros criterios por los cuales podemos configurar un poco el resultado que queremos obtener. De todos ellos, el que creo que es más interesante explicar es este de aquí, que es el engine. Realmente GPT-3 no es una única inteligencia artificial, sino es una familia de modelos. Tenemos dos familias de modelos y para cada uno de ellos tenemos diferentes tamaños de GPT-3. Para cada grupo tenemos ordenados de mayor a menor diferentes tamaños de modelos, donde los mayores serán más potentes, te darán mejores respuestas a tus problemas, serán más lentos también a la hora de generar sus resultados y también más caros. Porque sí, esto cuesta dinero. Ahora vamos a ver ese punto. Modelos como Hada serán más baratos, más rápidos y estarán destinados, por ejemplo, a resolver tareas más sencillas. Sin embargo, de este menú lo que me gustaría comentar es la diferencia entre los modelos base de los modelos instrag. Esto es algo que no he comentado en el canal de YouTube puesto que es una incorporación de los últimos meses, pero es muy interesante. En el modelo habitual de GPT-3 muchos sabréis que lo importante es cómo defines el contexto del problema que quieres que resuelva. En este caso podéis ver que si yo por ejemplo quiero crear un sistema que pueda responder automáticamente e-mails en base a una serie de topics que yo puedo definir, lo que tendría que hacer sería primero mostrarle ejemplos a GPT-3 de lo que quiero que haga. En este caso podría ser una serie, un listado de topics y redactar un e-mail que se parezca a lo que yo quiero que este sistema genere. Esto me permitiría que por ejemplo ahora yo pueda redactar una serie de topics y darle a generar y que GPT-3 pueda continuar completando la tarea que yo le he especificado. No estoy contento con la última campaña, no se han cumplido los términos del contrato, tendréis noticias de los abogados de mi agencia, estoy disponible para encontrar una solución amistosa y ahora yo podría coger aquí, siguiendo el formato de antes, poner e-mail dos puntos y que GPT-3 intenta ver si resuelve esta tarea, me genere un e-mail. Buenas tardes, no estoy contento con las campañas pasadas y por ello informo que no estoy dispuesto a continuar con las mismas condiciones. No se han cumplido los términos de nuestro contrato y por ello informo que os enviaré noticias de mi agencia. Estoy disponible para encontrar una solución amistosa, pero eso es algo que no depende de mí. Un saludo, Carlos Santana Vella. Vemos que más o menos GPT-3 ha podido hacer esa tarea que nosotros le hemos pedido, pero siempre ha apoyado en cómo nosotros hemos planteado el contexto anterior. Algo que además nos obliga a jugar bastante con el input. A lo mejor este formato con el que yo he planteado este problema no es el correcto y habría alguna otra forma diferente o a lo mejor hace falta más ejemplo de emails para llegar a una solución que a mí me satisfaga. Pero esto se ha vuelto mucho más sencillo con estas nuevas versiones de GPT-3 que son los modos Instruct, que están todavía en beta, y donde la cosa cambia por completo. En este caso los modos Instruct están pensados para que tú puedas plantearle lo que quieres que haga el modelo directamente como una instrucción, como una orden y no tanto basándote en ejemplo de cómo quieres que sea ese problema. En este caso lo único que le voy a pasar como input es la instrucción de que quiero que redacte un email basándose en los siguientes topics. Y vamos a ver qué tal desempeña su trabajo, a ver si sabe que tiene que escribir un email. En este caso, pues mira, podemos ver que sí, lo ha hecho en inglés. Le voy a pedir aquí ahora que lo haga en español. Redáctalo en español. Y vemos como el sistema empieza a obedecer a las instrucciones que nosotros le damos como input. En este caso el email es mucho más sencillo, yo creo que para esta tarea pues sí tendría sentido darle un email de ejemplo. Pero podéis ver cómo podéis trabajar con esta versión más orientada a plantear cada problema como una serie de instrucciones más que una serie de ejemplos. Antes en GPT-3 si tú querías hacer un diálogo pues tenías que empezar planteando el esquema de un diálogo, ahora con este sistema pues simplemente le tienes que dar la instrucción de quiero que desarrolles un diálogo filosófico que esté centrado en el origen del universo. Uno de los personajes será QuantumFracture, un importante youtuber español de física. Vamos a ver si funciona. QuantumFracture, ¿sabes que el origen del universo no es ni materia ni energía? ¿Qué es entonces? El origen del universo no tiene explicación. Nosotros lo llamamos el Big Bang y eso es todo. Bla bla bla. No sé si os dais cuenta de que ya todos tenéis acceso a esta tecnología y que podéis empezar a integrarlo por ejemplo con herramientas como Unity para crear videojuegos mucho más interesante donde puedas tener conversaciones con personajes que sean como estas y no sé, madre mía, se vienen cosas muy muy chulas. Y esta es la cosa, si queréis integrarlo en vuestros proyectos esto es muy sencillo. En este caso estamos trabajando a través del Playground que nos ofrece la página web de OpenAI pero fácilmente, por ejemplo, para esta configuración que tenemos aquí podemos irnos a este botón de aquí arriba y darle a View Code y ya nos van a mostrar directamente lo que sería el código necesario para, por ejemplo, en Python o cualquier otro tipo de alternativa. El código necesario para poder hacer la llamada a esta API y empezar a trabajar dentro del código con las respuestas que genere GPT-3. Si por ejemplo quisiera conectarme desde WorldCollab, pues primero tendría que instalar la librería de OpenAI. Una vez ya lo tenemos instalado pues simplemente sería conectarnos a la API de OpenAI, lo único que tendríamos que configurar aquí sería nuestra API Key, nuestra clave para conectarnos a la API, algo que es secreto y evidentemente no tenemos que compartir. Esto lo vamos a encontrar en la web de OpenAI en la documentación, aquí tendríamos pues para copiarla, nos la llevaríamos al código y una vez ya lo tengamos todo configurado pues es hacer peticiones a la API con la configuración que nosotros queramos. Podemos trabajar desde el Playground, buscar ahí la configuración que mejor nos convenga y luego copiar el código que ellos nos proporcionan. En este caso si lo ejecuto pues podemos ver que para la instrucción que habíamos puesto antes en el Engine de DaVinci Instruct Beta pues tenemos la respuesta, en este caso pues el debate en este discurso. Con esto así de sencillo podéis empezar a integrar esto en vuestro código. ¿Significa esto que ahora podemos utilizar esta tecnología en nuestros proyectos sin ninguna limitación? Sí, pero bueno, limitación sí hay y una de ellas es bastante importante y es el precio. Si os habéis loqueado en la página web de OpenAI y ya estáis jugando con todo este sistema tranquilos, no os van a cobrar porque OpenAI amablemente nos permite gastar hasta 18 dólares que ellos nos proporcionan de manera gratuita para probar el sistema y ver que realmente funciona y que nos interesa. Pero una vez que se agoten estos 18 dólares pues evidentemente tocará pagar por este servicio y esto es normal. Pensad que para que un sistema de inteligencia artificial como gbt3 funcione en una API como esta, pues la infraestructura necesaria tiene que ser enorme y tiene un coste bastante alto puesto que este sistema está desplegado en varias GPUs al mismo tiempo y ya os digo yo que esto por mucho Microsoft Azure que haya por detrás no es barato. ¿Cuánto cuesta? Pues depende del modelo que quieras utilizar. Los modelos más rápidos y menos potentes como el Ada o el Babbage pues tienen un precio de 0,0008 dólares por mil tokens y los más caros, el gbt3 más potente, el DaVinci, pues tiene un precio de 0,06 dólares por mil tokens. ¿Y a qué se refieren con estos tokens? Pues bueno, si hubiera visto mi vídeo sobre cómo funcionan estos sistemas de procesamiento de lenguaje natural lo sabrías, hay uno que se llama explícitamente de texto a tokens, pero tranquilo, te lo explico. Al final estos sistemas se basan en transformers que se nutren de secuencias de palabras que son dados como input y van a generar otra secuencia de palabras. Esta secuencia de palabras las podemos subdividir por tokens. Estos tokens podrían ser una frase entera, podría ser una palabra o en el caso de gbt3 podrían ser trozos de palabras. En este caso la gente de OpenAI ha compartido una herramienta muy interesante que es esto de aquí, el tokenizador, para poder comprobar cuántos tokens conforman a tu input y así poderte hacer una idea de cuánto te podría costar. Aquí podría poner pues Hola soy Carlos este tokenizador y aquí abajo podríamos ver que esto se compone de 13 tokens donde la palabra está dividida de esta manera. Hola soy Carlos y estoy probando este tokenizador. Así que ya sabéis, depende del modelo que queráis utilizar y de cuántos tokens conformen a tu input te costará más o menos. Un poco la conversión que podríamos tener en la cabeza es la que nos comentan por aquí. Puedes pensar en los tokens como trozos de palabras donde mil tokens son más o menos 750 palabras en inglés. Este párrafo por ejemplo pues serían 35 tokens y para que os hagáis una idea pues os voy a enseñar un poco cuál ha sido el consumo que yo he hecho durante la última hora en la grabación de este vídeo. Todos los ejemplos que habéis visto pues cuántos tokens ha consumido y cuántos dólares me han costado. En este caso podemos ver en esta gráfica de aquí que esto ha sido un total de más o menos 7000 tokens donde parte de ellos la mayoría ha ido por input y parte de ello lo que está morado ha sido la completación que ha hecho GPT 3. Tanto el input como lo que te completa GPT 3 ese número de tokens son los que se te van a cobrar y en este caso esto suma un total de 0 42 dólares lo cual realmente es un precio bastante asequible para poder al menos a nivel individual hacer proyectos interesantes. La cosa se vuelve más complicada si esto después lo conviertes tú en un producto donde estás haciendo uso de esta API y lo pones al servicio de muchos usuarios pues por ejemplo pensemos un videojuego donde cualquier persona pueda interactuar con los personajes y por tanto todos estén consumiendo de tu API. Ahí es donde vas a tener que tener un control real de los gastos que puede suponer estar utilizando GPT 3. Pero esa no es la única limitación que vas a tener si quieres hacer una aplicación que se va a convertir en algo real que la gente pueda utilizar antes vas a tener que pasar por la revisión de la gente de OpenAI y es que la apertura de la API evidentemente lleva ligado una serie de controles muy importantes ya que a OpenAI le ha preocupado desde el primer momento que no haya un mal uso de esta tecnología y por tanto vas a tener que pasar por la supervisión del equipo detrás de todo esto. Es por eso que os recomiendo muchísimo que si no queréis ser baneados de la API de GPT 3 dediquéis un tiempo importante a leer la documentación sobre cuáles son las políticas de lanzar una aplicación al mercado de cómo lo tenéis que utilizar de cómo podéis compartir resultados a través de internet todo esto está bien detallado en su página web y yo digo OpenAI se está tomando esto muy en serio y de haber abierto esta herramienta al público pues tiene unas fuertes medidas de control que todos deberíamos de respetar para que esto funcione como tiene que funcionar. Por ejemplo OpenAI estará bloqueando aplicaciones que se usen para generar tuits automáticos o post de Instagram chatbot que no estén limitados. Aplicaciones que se utilizan por ejemplo para generar artículos masivos que bueno se quieran colocar en post donde se quiera mejorar el SEO de una forma automática. Es decir cualquier mal uso que se puede imaginar para esta aplicación OpenAI va a estar persiguiendo así que de nuevo dedícale tiempo a leer la documentación. Y mi último consejo es que dediquéis un tiempo a ver todos los ejemplos que os proporcionan en la web de OpenAI. Hay un montón de ejemplos de uso de cómo podéis utilizar esto para ser traductores para ser sistemas de lenguaje natural para hacer clasificación para convertir una película a un emoji. Montón de ejemplos super interesantes y originales y creativos que os van a permitir entender mejor cómo funciona este sistema. Lo bonito que ha tenido GPT-3 desde el comienzo es que ha sido una enorme inteligencia artificial que entre todos hemos ido explorando cuáles son sus capacidades a través de jugar con el input y ahora todo el mundo tiene la posibilidad de acceder a esto e integrarlo en sus proyectos. Creo que estamos entrando en una fase muy interesante donde por primera vez tenemos un acceso masivo a una herramienta tan potente como GPT-3 y ahora es vuestro turno. Quiero que desarrolléis cosas que aprovechéis este sistema pues para potenciar vuestras ideas vuestros productos y que si hacéis algo interesante pues que quiero que lo compartáis y que lo pongáis en redes sociales, me etiquetéis y yo así le echaré un vistazo y lo compartiré también para que el resto de las personas lo veáis. Este vídeo pretende ser además un impulso a toda esta ola que OpenAI está motivando así que si conocéis gente que pueda desconocer de esta tecnología y que podría aplicarla de forma muy interesante pues os invito a compartir este vídeo en vuestras comunidades desarrolladores, grupos de whatsapp o amigos que conozcáis de la Facultad de Informática. Yo soy DotSesue, ya sabéis que aquí hemos hablado de Inteligencia Artificial durante mucho tiempo y hemos hablado de estos sistemas. Tenéis un montón de vídeos para entender cómo funciona por detrás, de hecho el vídeo del domingo pasado era parte de la explicación que nos permite entender de dónde surge el éxito de sistemas como GPT-3, por qué los Transformers han posibilitado tener tecnologías como esta en muy poquito tiempo. Sé que es un vídeo que por las estadísticas mucha gente no ha visto y en parte es porque YouTube no lo ha notificado así que os aviso que si queréis entender mejor cómo funcionan los Transformers lo tenéis disponible en mi canal, podéis cliccarme por aquí justo ya que estamos terminando y con esto podéis verlo. Chicos, chicas, esto es la revolución de la IA, está no empezando sino continuando y aquí en DotSesue os la seguiré comentando. Muchas gracias y nos vemos en el próximo vídeo.
