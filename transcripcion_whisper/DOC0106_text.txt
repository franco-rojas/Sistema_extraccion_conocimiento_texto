 En un video anterior vimos cómo usar los sets de entrenamiento, validación y prueba para encontrar los parámetros y perparámetros de un modelo y para elegir el mejor modelo de entre varios posibles. Sin embargo, no siempre resulta conveniente usar este enfoque y muchas veces es más adecuado usar un enfoque que se conoce como la validación cruzada. Así que en este video vamos a entender qué es la validación cruzada y cómo funciona el K-Fault-Cross Validation que es uno de los principales métodos o algoritmos utilizados para realizar precisamente esta validación. Pero antes de comenzar los invito a visitar codificandovids.com en donde encontrarán la Academia Online con cursos de Inteligencia Artificial Ciencia de Datos y Machine Learning que les permitirán construir su carrera en estas áreas y todo por una suscripción mensual de tan solo 10 dólares. Así que listo, comencemos. Antes de ver qué es la validación cruzada vale la pena recordar que son los parámetros y perparámetros de un modelo algo de lo que ya hablamos en detalle en un video anterior y recordemos también que uno de los objetivos del Machine Learning es construir un modelo que tome unos datos de entrada y que sea capaz de generar predicciones sobre esos datos. Cuando construimos el modelo lo que buscamos es encontrar una serie de parámetros que son simplemente los coeficientes numéricos internos del modelo y que se encuentran durante el proceso de entrenamiento. Además para construir ese modelo debemos definir los hiperparámetros que son también unos coeficientes numéricos pero que nosotros como programadores del algoritmo de entrenamiento tenemos que definir buscando generar las mejores predicciones posibles. Además usualmente es necesario entrenar múltiples modelos con diferentes parámetros e hiperparámetros para posteriormente elegir cuál es el más adecuado de todos estos modelos para el problema que estamos intentando resolver. Y para lograr esto debemos ajustar los parámetros e hiperparámetros de cada modelo medir su desempeño y escoger el modelo que genere las mejores predicciones posibles. Y en todo esto entra en juego un concepto muy importante que se conoce como la capacidad de generalización del modelo que es simplemente su capacidad de generar buenas predicciones sobre datos que no ha visto previamente. Entendamos esto con un ejemplo. Supongamos que queremos construir un modelo que tome variables como el peso, la edad y algunos hábitos de las personas como la cantidad de horas de ejercicio que hace semanalmente por ejemplo y con ello prediga si el sujeto tiene o no problemas cardíacos. De nada sirve contar con un modelo que durante el entrenamiento acierte en la clasificación el 99% de las veces si al momento de presentarle nuevos datos que nunca antes ha procesado esta tasa de acierto se reduzca tan solo el 70%. Es decir, lo ideal sería que en condiciones reales con datos nunca antes vistos este desempeño sea cercano al 99% obtenido en el entrenamiento. Y para entrenar el modelo y evaluar su capacidad de generalización podríamos usar precisamente los sets de entrenamiento, validación y prueba. Así que a continuación voy a hacer un pequeño resumen de este método pero si quieren ver en detalle en qué consiste les dejo abajo el enlace del video correspondiente. Con este enfoque tomamos nuestro set de datos y lo partimos en tres. entrenamiento con aproximadamente el 70% de los datos validación y prueba cada uno con aproximadamente el 15% de los datos. El set de entrenamiento nos permite obtener los parámetros del modelo y el de validación nos permite ajustar los hiperparámetros y seleccionar el mejor modelo entre varios posibles. Mientras que el set de prueba nos permite medir la capacidad de generalización del modelo. El problema de este enfoque es que para poder usarlo generalmente requerimos muchos datos generalmente cientos de miles o incluso millones y esto no resulta siempre viable pero además puede ocurrir que al hacer la partición no necesariamente estos tres subsets tengan las mismas distribuciones. Entonces es posible que por ejemplo el set de entrenamiento tenga datos ligeramente diferentes de los sets de validación y prueba y esto va a afectar el entrenamiento y validación del modelo. Y por otra parte al ajustar los parámetros y hiperparámetros del modelo siempre con los mismos sets de datos los de entrenamiento y validación podemos llevar al modelo algo que se conoce como el sobreajuste es decir que el modelo va a tender a memorizar esos datos de entrenamiento y validación y no va a funcionar adecuadamente cuando le presentemos por ejemplo los datos provenientes del set de prueba. Y la validación cruzada es precisamente una alternativa a todos estos inconvenientes que acabo de mencionarles así que veamos en detalle en qué consiste esta validación cruzada. La idea de la validación cruzada es muy simple en lugar de usar diferentes sets para entrenamiento, validación y prueba en la validación cruzada vamos a usar la totalidad de los datos y aunque existen muchos métodos para lograr este objetivo uno de los más usados es el de la validación cruzada de K iteraciones más conocida por su término en inglés K-Fault-Cross-Validation así que en lo que queda de este video nos enfocaremos en este tipo de validación entonces comencemos viendo en qué consiste el algoritmo y luego lo entenderemos en detalle a través de un ejemplo. El algoritmo comienza con la mezcla aleatoria de los datos y con la inicialización del parámetro K que es simplemente un número entero que definirá el número de particiones de nuestro set de datos así como el número de iteraciones de entrenamiento y validación que se usarán al construir el modelo esto es lo que le da el nombre precisamente a este algoritmo. Una vez definido el parámetro K inicia este proceso de entrenamiento y validación así que por un total de K iteraciones se repiten estos pasos se toma una de las K particiones y se mantiene oculta al modelo se toman las K-1 particiones restantes y con ellas se entrena el modelo es decir se calculan de forma automática a través del algoritmo de entrenamiento los parámetros y una vez entrenado el modelo se almacena su desempeño obtenido con el set de entrenamiento K-1 particiones y con el set de datos oculto la partición restante y luego se repiten los tres pasos anteriores pero cambiando la partición que se mantiene oculta y una vez terminadas las iteraciones tendremos K medidas de desempeño para los sets de entrenamiento y validación usados en cada iteración así que el desempeño final del modelo será simplemente el promedio de los desempeños anteriores Entendamos el algoritmo anterior con un ejemplo práctico entonces supongamos que volvemos al caso hipotético del modelo que queremos construir para determinar si una persona tiene o no problemas cardíacos y para simplificar las cosas supondremos un set de datos muy pequeño tan solo 12 datos y vamos a asumir que mediremos el desempeño como la exactitud del total de datos introducidos al modelo cuantas predicciones son correctas en este caso el algoritmo comienza con la mezcla aleatoria de los datos con lo cual podremos garantizar que el orden en el que presentamos los datos al modelo no afectará su desempeño ahora sumamos que el valor de K es igual a 3 es decir que partiremos el set de 12 datos en 3 bloques o faults cada uno con un total de 4 datos y ahora comenzamos las iteraciones de entrenamiento y validación como el valor de K es igual a 3 realizaremos 3 iteraciones en la primera iteración ocultamos el bloque 1 y usamos los bloques 2 y 3 para entrenar el modelo y una vez entrenado le presentamos el bloque 1 y lo validamos supongamos que tras este procedimiento obtenemos un desempeño con el set de entrenamiento igual al 82% y con el set de validación igual al 80% almacenamos estos dos valores en dos listas independientes y continuamos con las iteraciones en la segunda iteración repetimos los mismos pasos de la iteración anterior con la diferencia de que ahora debemos cambiar el bloque oculto supongamos que en este caso ocultamos el bloque 2 y que entrenamos el modelo con los bloques 1 y 3 tras el entrenamiento validamos el modelo con el bloque 2 y almacenamos en los listados anteriores los desempeños obtenidos 84% para entrenamiento y 81% para validación y llegamos finalmente a la tercera iteración en donde ocultamos el bloque 3 y usamos los bloques 1 y 2 para entrenar obteniendo al final de todo esto desempeños del 80% para los dos bloques de entrenamiento y del 79% para el bloque de validación perfecto terminadas las iteraciones el último paso del algoritmo es determinar el desempeño final del modelo durante el entrenamiento y la validación para el caso del entrenamiento simplemente tomamos los desempeños obtenidos durante las tres iteraciones de entrenamiento es decir 82, 84 y 80% y los promediamos obteniendo una exactitud promedio del 82% y hacemos algo similar con los desempeños obtenidos durante las tres evaluaciones es decir 80, 81 y 79% obteniendo una exactitud promedio del 80% acá vemos que los desempeños durante el entrenamiento y la validación son muy similares y por tanto podemos concluir que el modelo no tiene ningún sobre ajuste y que ha sido entrenado y validado correctamente y que además de esto tiene una buena capacidad de generalización pues la exactitud promedio de validación es muy cercana a la obtenida durante el entrenamiento una pregunta obvia que surge tras haber visto cómo funciona el algoritmo es cuál es el número adecuado de particiones es decir cuál es ese valor ideal que debe tener el parámetro K y en realidad no existe una única respuesta pues todo depende del modelo que estemos construyendo y de los datos con que lo estemos alimentando sin embargo podemos analizar algunas situaciones extremas y con base en esto definir un rango de valores de K que podría resultar adecuado si escogemos el valor de K más pequeño posible es decir 2 tendremos tan solo dos particiones y es posible que el modelo no detecte adecuadamente los patrones en los datos lo que hace que la mayoría de las predicciones sean erróneas por otra parte si escogemos un valor de K muy grande comparado con el tamaño del set de datos tendremos demasiadas particiones y cada una de ellas contendrá muy pocos datos esto hará que haya demasiada variabilidad en el desempeño entre una y otra partición y por tanto el entrenamiento y la validación no van a ser fiables además si nuestro set de datos tiene muchos datos y a la vez usamos demasiadas particiones requeriremos muchos más recursos computacionales para el entrenamiento y la validación así que usualmente lo que se hace es usar valores intermedios de K dependiendo del tamaño del set de datos es decir ni muy pequeños ni muy grandes por ejemplo cuando tenemos unos cuantos cientos o algunos miles de datos generalmente podríamos usar valores de K iguales a 5, 10 o 20 y lo que sí podemos hacer es entrenar y validar el modelo con estos tres diferentes valores de K y verificar cuál de ellos nos genera los mejores resultados para el modelo que estemos entrenando y para los datos que estemos utilizando muy bien, acabamos de ver en qué consiste la validación cruzada y uno de los algoritmos más usados en esta metodología que es el algoritmo de K-Faultless Validation esta validación cruzada es una alternativa a la partición del set de datos en entrenamiento, validación y prueba del cual hablamos en un vídeo anterior y tiene además varias ventajas con respecto a ese método la primera de ellas es que funciona en casos para los cuales tenemos relativamente pocos datos por ejemplo unos cuantos cientos o unos pocos miles la segunda ventaja es que nos da una validación más robusta porque estamos entrenando el modelo y validándolo con la totalidad de los datos y esto nos puede dar una medida más precisa de cuál es la capacidad de generalización del modelo y la tercera ventaja es que al entrenar y validar el modelo con la totalidad de los datos estamos reduciendo esa probabilidad de overfitting o sobreajuste del modelo y esto nuevamente mejora su capacidad de generalización sin embargo, tal vez una de las principales desventajas de este método es su costo computacional pues al tener muchos datos, muchas particiones tendremos que llevar a cabo múltiples iteraciones de entrenamiento y validación en comparación con el enfoque de el set de entrenamiento, validación y prueba muy bien, recuerden que si tienen alguna de lo que acabamos de ver en este vídeo me la pueden dejar abajo en los comentarios y recuerden también que si les gustó el vídeo los invito a darle un pulgar hacia arriba de me gusta y a compartirlo con todos sus amigos y conocidos pues esto me ayudará a seguir llegando cada vez a más y más personas y si aún no lo han hecho, los invito a suscribirse al canal y activar la campanita para que YouTube les notifique cada vez que publique un nuevo vídeo por ahora esto es todo, les envío un saludo y nos vemos en el próximo vídeo
