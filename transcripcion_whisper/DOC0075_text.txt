 Hasta este momento ya tenemos muchas opciones de modelos inteligentes para generar texto. Tenemos a GPT-3 y GPT-4, que se pueden utilizar desde ChatGPT. Tenemos Lambda, que se puede utilizar desde Google Bars, el competidor directo de ChatGPT. Y en el open source ya tenemos una lista mucho más grande como lo sería Lama, Koala, Vicuña y varios modelos abiertos que si bien no son muy usados, si están ayudando a impulsar más el avance de los Large Language Models. Pero como el generar texto e imágenes ya se está volviendo más común, ahora el siguiente paso que se está investigando es permitir que estos modelos hagan tareas más complejas. Es decir, que puedan crear archivos, ejecutar código, hacer búsquedas en internet, procesar archivos de imágenes y no por separado, sino más bien en conjunto. Es decir, que en lugar de que le pidas una porción de código y uno de estos modelos te responda con texto, mejor pídele que te crea un sitio completo y que él mismo se encarre de desplegarlo, testearlo y ejecutar todo el código, además de todos los archivos necesarios para que funcione. Por supuesto, para esto se tiene que dar acceso a tu sistema para poder hacer todo esto. Así que hay proyectos open source que te están permitiendo probar este tipo de tareas en los que podríamos encontrar a Hanging GPT, Auto GPT y Baby AGI, que les daré más información de estos en unos segundos. Y además de eso también están los frameworks que te permiten hacer todas estas tareas usando tu propio código, como sería el proyecto Land Chain. Ahora todo esto de hecho está haciendo que muchos entusiastas se estén empezando a preguntar Si desarrollando todo esto, estaremos llegando realmente a lo que sería una AGI de Artificial General Intelligence o una Inteligencia Artificial General. Verán, muchos investigadores durante muchos años han soñado con una AGI, ya que cuando se habla de inteligencia artificial siempre se piensa en una máquina capaz de hacer todas las tareas que hace un ser humano o incluso hacerlas mejor que un humano, teniendo la capacidad de aprender de todo. Y aunque no hay una definición muy precisa para lo que es una AGI ya que se ha investigado esto durante mucho tiempo, al parecer con todos estos pequeños avances relativamente, parece que estuvieramos viendo chispas de AGI. De hecho, este es el nombre de un paper de Microsoft llamado Sparf of Artificial General Intelligence, Early Experiments with GPT-4, en donde el estudio demuestra la capacidad de GPT-4 para lograr un rendimiento a nivel humano en tareas novedosas y difíciles en dominios que van desde las matemáticas, la codificación, hasta la visión, la medicina, el derecho y la psicología. Y concluye que podría verse razonablemente como una versión temprana, pero aún incompleta, de un sistema de Inteligencia Artificial General. Ya que el interés por desarrollar estos modelos y hacerlos cada vez mejores va en aumento. De hecho, si vemos un gráfico de la cantidad de investigaciones que se publican cada mes en Archive, un sitio que aloja las prepublicaciones de artículos científicos en distintos campos como la matemática, la física, las ciencias de la computación o la biología cuantitativa, estamos viendo que el sitio está alojando muchas más publicaciones desde el año 2021. Y actualmente con el impulso de modelos open source, esto solo está aumentando. Y no solo esto, sino que la capacidad de los parámetros que se están utilizando en los modelos actuales también se está incrementando exponencialmente. Y aunque el aumento de parámetros no nos hará llegar a niveles de AGI, sí se está empezando a ver avances notorios, gracias al impulso de modelos como GPT-4 que ahora pueden entrenarse a sí mismos. Eso fue revelado hace una semana en un paper llamado Reflection, en donde se habla de agentes inteligentes que pueden emular las autorreflexiones humanas para que puedan evaluar su propio rendimiento, similar a como lo hacen los humanos. Por ejemplo, usando la prueba HumanEval de OpenAI, que consiste en 164 problemas de Python que el modelo nunca ha visto, este respondió a 67% correctamente. Pero con la capacidad de autorreflexión ha llegado al 88%. Y no solo esto, sino que la comunidad no está esperando que OpenAI haga todo. Es por esto que modelos que están disponibles actualmente, además de GPT-4, están siendo combinados para que cada uno procese una tarea distinta y en conjunto pueden hacer tareas más complejas. Por ejemplo, este es Hagen GPT, un proyecto que usa GPT-4 como cerebro y que es capaz de delegar tareas a otros modelos abiertos que están alojados en Hagenface, un sitio donde se alojan proyectos AI open source. Y aunque tiende a ser muy básico estos tipos de ejemplos, esta es una prueba de concepto bastante interesante. Luego también tenemos a AutoGPT, que este es otro proyecto abierto, potencial por GPT-4, que puede darse prompts a sí mismo para completar de manera eficiente múltiples tareas, a través de textos encadenados y reflexión, pudiendo desde descargar archivos, escribir código y ejecutar scripts, que según su autor, este permite hacer desde debugging recursivamente hasta desarrollar proyectos completos. De hecho, este es el proyecto llamado la atención de Andrew Carpathy de OpenAI, llamándolo la siguiente frontera a alcanzar por estos modelos inteligentes. Luego también está RoboGPT, que es un proyecto similar y más simple a AutoGPT, que puede darles tareas desde consola e irá paso a paso mencionando lo que está haciendo, usando paquetes que convierte texto a voz, permitiendo que pueda solicitar código, lo guarde en un archivo, lo ejecute y vuelva a reescribirlo, hasta que cumpla con lo que le ha solicitado, aunque para proyectos bastante pequeños. Por ejemplo, aquí está obteniendo datos de los mejores lugares para nomadadigitales y al final lo guarde en un archivo CSV. Y finalmente también está BabyAGI, que es bastante similar a lo que ofrece AutoGPT y que también es un proyecto open source. Y no solo queda aquí, sino que también se están creando proyectos en sentido contrario, es decir, que también sirvan para acciones maliciosas, en donde aquí podríamos mencionar a ChaosGPT, que basado en AutoGPT tiene el objetivo de crear agentes y a maliciosos, usando GPT para entrenamiento, pero intentando evitar estos filtros amistosos que OpenAI siempre coloca a estos modelos. Ahora, como un ejemplo práctico, algo que podríamos ver a futuro. Está por ejemplo un proyecto personal por parte de un usuario de Twitter, en donde he mostrado cómo hablando con Siri puede pedirle con voz que crea una aplicación, dándole instrucciones de qué es lo que quiere, y que éste se conecte a una base de datos que pueda ejecutar códigos, se conecte a SuperBase, que es un servicio similar a Firebase, y finalmente que despliegue el proyecto en versed. Todo esto solo utilizando la voz. Y ahora, vamos a ver cómo se puede hacer con la aplicación. En este caso, vamos a usar la aplicación de la aplicación. Y vamos a ver cómo se puede hacer con la aplicación. Y ahora, vamos a ver cómo se puede hacer con la aplicación. Y ahora, vamos a ver cómo se puede hacer con la aplicación. Y ahora, vamos a ver cómo se puede hacer con la aplicación. Y ahora, vamos a ver cómo se puede hacer con la aplicación. Y ahora, vamos a ver cómo se puede hacer con la aplicación. Y ahora, vamos a ver cómo se puede hacer con la aplicación. Aquí va. Oh, sí, es muy rápido. Oh, esto va rápido. ¡Bum! Modo oscuro. Vamos a ver si está respondiendo. Ok, ahora está bien. Ok, ahora tenemos que probarlo. Ok, debemos poder submitirlo y esto debería funcionar. Profile creado sucesivamente. Ok, ok. Se muestra el profile. Vemos que tenemos una lista de todos los profiles. Vamos a clicar en eso. Ok, esto nos muestra los profiles. Ahora vamos a... Vamos a que esto esté respondiendo. ¡Sí, sí! Y si vamos a nuestra database, está en nuestra dv. Vamos a ver cómo se puede hacer con la aplicación. ¡Oh, sí! Ahora, todo esto es bastante interesante, pero con cada avance lo principal que se está probando es la automatización de creación de aplicaciones. Ahora, todo esto es bastante interesante, pero con cada avance lo principal que se está probando es la automatización de creación de aplicaciones. Es decir, que las aplicaciones se generen por sí mismas. Y esto está preocupando a muchos iniciantes en programación. Así que muchos están preguntando si vale la pena seguir aprendiendo programación o si debería haber un nuevo método de aprendizaje en todo caso. Pero esto lo trataré el día de mañana, ya que eso te va un poco más extenso. Así que nos vemos en el siguiente vídeo.
