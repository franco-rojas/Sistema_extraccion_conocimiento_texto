 Si me preguntaron cuál ha sido el avance científico más relevante del año 2020, podría elegir entre varias cosas, la verdad que ha sido un año bastante interesante y donde el campo de la inteligencia artificial también nos ha dejado con grandes titulares. De todos ellos, hoy elijo uno. Unos resultados que son bastante recientes del mes pasado y que no sólo consolidan a la inteligencia artificial como una herramienta muy importante a nivel científico, sino que también podría ser una tecnología revolucionaria dentro del campo de la biología, al haberse resuelto uno de los grandes problemas dentro de este campo. En el vídeo de hoy hablaremos de alfafol 2 y el problema del plegamiento de las proteínas. Y si vamos a hablar de biomedicina, de proteínas y demás cosas bonitas, pues para eso tengo a la invitada perfecta, a Sandra Hortonoves, que la voy a invocar... ¿Ahora es cuando entra? No voy a cortar nada de esto. No, por favor, corta eso. Pero si no se me ve... Está moviendo el cable de alguna manera. ¿Sabes qué? Todo esto va a salir. Todo esto va a ser raín. Por favor, por favor. Por favor. Sandra Hortonoves, del canal La Hyperactina, donde se dedica a hablar de proteínas, biomedicina y cosas de estas que no conozco. Hoy Sandra ha venido aquí a ayudarnos a comprender mejor toda la naturaleza de este problema del plegamiento de proteínas que soluciona alfafol, ¿vale? Y esto lo vamos a hacer en dos vídeos, en dos colaboraciones que tenéis disponibles. Uno es este vídeo, donde vais a entender más cómo funciona alfafol. Y otro básicamente es mi vídeo, en el cual vamos a hablar un poco más largo y tendido de las proteínas, del plegamiento y de cómo alfafol nos va a ayudar mucho en biomedicina. Así que vamos a empezar primero con la parte biomedica del asunto. Las proteínas, moléculas indispensables para la vida, se tratan de una secuencia de unas moléculas más pequeñas llamadas aminoácidos. Pero más allá de ser una simple cadena de aminoácidos, las proteínas son las moléculas más complejas y sofisticadas que se conocen y eso es debido en parte a su plegamiento. Cada tipo de proteína, ya sea una hemoglobina o un anticuerpo, tiene una estructura tridimensional única que viene marcada por esa secuencia de aminoácidos. Es decir, según los aminoácidos que la formen, esa proteína se va a plegar de una forma u otra. No solo eso, sino que si una proteína está mal plegada, va a ser por una parte incapaz de realizar esa función, lo cual puede ser letal para la célula, pero es que además puede dar lugar a enfermedades tan conocidas como el Alzheimer o el Parkinson. De todos modos, tenéis este tema mucho más ampliado y detallado en mi canal, en el que le damos más caña a esta parte biomédica del asunto. Pero aquí vamos a hablar de inteligencia artificial. Efectivamente, aquí nos vamos a centrar más en entender cómo funciona AlphaFold. Y ya está la historia. Si quieres incentivar a mucha gente a participar en la resolución de este problema, ¿cómo podrías conseguirlo? Pues, por ejemplo, planteando una competición. Una competición donde se les pidiera a los participantes que para una secuencia de aminoácidos dada, que pertenece a una proteína cuya estructura es desconocida por ellos, generen métodos de modelado que puedan predecir cuál podría ser esta estructura. El resultado generado se comparará con el resultado real, obtenido con otro tipo de técnicas mucho más costosas que ya mencionaremos luego, y finalmente se evaluará quién ha obtenido el mejor resultado. Vamos, una competición típica. Esta competición es la Critical Assessment of Protein Structure Prediction o CASP. Y se viene realizando cada dos años desde 1994. Esta competición no sería noticia en este canal, sino fuera porque una empresa tan poco conocida como es DeepMind, no siendo un laboratorio que se dedica al problema del plegado de proteínas, ni siendo este su campo de estudio, se metieron a participar utilizando todas estas herramientas de deep learning que conocemos y bueno, pues quedaron primeros. Cada una de estas barras representa la puntuación total obtenida por cada equipo participante y podemos ver que en 2018, participando, repito de nuevo, por primera vez, DeepMind con su sistema AlphaFold quedó en primera posición, mostrando que efectivamente hacer uso de modelos de deep learning a la escala a la que lo hace DeepMind es una alternativa viable. Y esto ocurrió en 2018, pero dos años después, en 2020, esta competición se ha vuelto a repetir y como era de esperar, había muchos ojos puestos en AlphaFold y en cómo habría evolucionado. Y en efecto, los resultados publicados mostraron cómo AlphaFold 2, a nueva versión, consiguió una puntuación impresionante y que dejaba clara la gran diferencia que existía entre los resultados de DeepMind y el resto de participantes. Como es lógico, los resultados dejaron flipando a la comunidad científica y en palabras de los organizadores, AlphaFold 2 habría resultado satisfactoriamente un desafío que permanecía abierto desde hacía 50 años cuando se planteó por primera vez. Carlos, tú que eres tan listo. A ver, ¿cómo lo han hecho? ¿Cómo funciona AlphaFold? Pues esto en realidad no es un problema sencillo, porque si lo pensamos aquí, lo que estamos haciendo es intentar predecir a partir de una secuencia unidimensional de datos, la secuencia de aminoácidos, cuál es la estructura tridimensional de la proteína, cuál es la posición que ocupa cada aminoácido en todo este espacio tridimensional, sacar toda su estructura. Y para llegar a esa estructura tenemos que fijarnos en las propiedades químicas que tienen los aminoácidos de esa secuencia de entrada. Más que nada para entender las dinámicas que hacen que poco a poco esa secuencia se vaya plegando hasta llegar a la estructura final. Si, por ejemplo, decidieramos ignorar todas estas dinámicas y directamente que la proteína se plegara de manera aleatoria, existiría un espacio de búsqueda donde para una proteína estándar de tamaño normal podrían existir tantas configuraciones que evaluar cada una de ellas requeriría más tiempo que la edad del universo. Una de estas frases que DeepMind disfruta tanto. Y claro, siendo esto así, pues es evidente que tenemos que atender a cómo funcionan estas dinámicas para poder comprender cómo se pliega realmente una proteína. Todas estas propiedades que ya hemos explicado en el vídeo del canal de Sandra. Y sí, cuando he dicho que tenemos que atender nosotros a cuáles son estas dinámicas no me refiero a nosotros, me refiero a un algoritmo de inteligencia artificial que aprenda a descubrir cuáles son estos patrones. Pequeño disclaimer, a ver, si bien los resultados de Alpha Fold 2 ya los conocemos los de la competición, hay que decir que todavía no se ha publicado ningún paper. Al igual que ocurrió con la competición de 2018 que salieron a finales de ese año y hasta principios de 2020 no tuvimos el paper en nature. Pero eso nos impide que podamos profundizar en este paper de la primera versión para ganar intuición de su funcionamiento y combinarlo con lo poco que sabemos para ver cómo ha evolucionado Alpha Fold 2. Y cuando lo hacemos descubrimos algo interesante y es que DeepMind se ha empeñado en convertir este problema de convertir una secuencia unidimensional a una estructura tridimensional en un problema diferente, en un problema de convertir una imagen a otra imagen. Veréis, como ya hemos visto muchas veces en el canal, muchas de las herramientas de inteligencia artificial que hemos desarrollado los últimos años se aplican sobre imágenes, encontrándonos uso donde con redes neuronales podemos tomar una imagen de entrada y convertirla a otra imagen de salida diferente, tomar una imagen y generar un mapa de segmentación, tomar una imagen y modificar su estilo, tomar una imagen y borrar un elemento. Todo eso es posible. Y son tan potentes estas redes que trabajan con imágenes que es habitual ver cómo en ocasiones hay problemas donde nuestros datos sin ser imágenes se adaptan para que lo sean y así podamos utilizar estas redes. Por ejemplo, es normal ver proyectos donde trabajando con la onda de audio, que es una secuencia, ésta la conviertan a su espectrograma, una imagen, para así continuar usando estas redes. ¿Eso de que cuando tienes un martillo todo te parece un clavo? Pues eso. Y en el caso de la primera versión de Alpha Fold la idea es similar. Lo que han hecho ha sido tomar esta secuencia de aminoácidos y de alguna manera convertirla a una imagen para que después un algoritmo de inteligencia artificial se encargue de traducirla a otra imagen que represente la estructura de la proteína. Vamos a centrarnos en los datos de entrada. Vamos a fijarnos qué información podemos extraer de nuestra secuencia de aminoácidos y que podemos suministrar a Alpha Fold. Para este tipo de problemas partimos de la secuencia de aminoácidos y una forma de extraer información de ella es a través de una técnica llamada M.C.A. o Multiple Sequence Aligned, que consiste en alinear y comparar muchísimas secuencias de aminoácidos, de proteínas de distintos seres vivos que tienen una relación evolutiva y por tanto su secuencia de aminoácidos es parecida. Al hacer esto es posible que veamos que en algunos casos se produzca el siguiente patrón. Cuando un aminoácido de la secuencia cambia debido a una mutación hay otro de esa secuencia que también cambia. Es decir, podemos ver cómo hay aminoácidos que de alguna forma están conectados y eso es así porque esos aminoácidos interaccionan dentro de la proteína. Como esa interacción es necesaria para mantener la estructura de la proteína, Si un aminoácido cambia debido a una mutación, el otro tiene que cambiar por nálides. Esos dos aminoácidos coevolucionan en el tiempo. De esta forma comparando muchas secuencias y viendo esos aminoácidos que coevolucionan podemos conocer qué interacciones se producen dentro de esa estructura tridimensional de la proteína que nos pueden ayudar a predecir cómo se va a plegar. Esta información de cómo interactúan dos aminoácidos que ocupan una posición diferente en la secuencia la podemos estudiar con diferentes estadísticos como la correlación y con esto podemos ir completando una matriz de datos que nos indique cómo interactúa cada aminoácido de la secuencia consigo mismo conformando una matriz de datos que se va a parecer a una imagen. Toda esta información queremos configurando en diferentes matrices de datos será la que le suministraremos como entrada a Alphafold. Y ahora, cito textualmente del paper, utilizamos redes neuronales cuya estructura son similares a las usadas para problemas de reconocimiento de imágenes. Las redes neuronales... venga, es tu parte que te gusta. ¡Convolucionales! Las redes neuronales... Lo que se busca es que la red aprenda a generar una imagen como esta. ¿Qué es? Pues lo creas o no, esta información representa la estructura tridimensional de la proteína. Fíjate bien en el resultado que genera Alphafold. Esto es un distograma y lo que viene a representar es la predicción que ha hecho la red de la distancia a la que se puede encontrar cada aminoácido de la secuencia dada como entrada. Mira, para que lo entiendas bien, imagínate que nuestra secuencia estuviera reducida a solo 5 aminoácidos y quisiéramos representar en esta matriz la distancia a la que se van a encontrar cada uno de ellos en el espacio tridimensional. El resultado de las distancias lo anotaremos en la siguiente matriz, donde cada celda va a representar cuál es la distancia de cada aminoácido de la proteína con el resto de los elementos. Evidentemente, cada aminoácido consigo mismo estará a una distancia de 0, que es el mismo elemento, así que en la matriz siempre encontraremos en la diagonal que la distancia es 0. Es normal que los aminoácidos cercanos en la secuencia se encuentren también a una distancia cercana en el espacio tridimensional, de ahí que aparezca esta franja amarilla de aquí representando su cercanía. Y luego, si sucede que nuestra proteína se ha plegado por la interacción entre dos partes de la cadena, veremos que también su cercanía quedará representada en la matriz. ¿Lo ves? Y es esta matriz, esta imagen, lo que la red neuronal aprenderá a predecir. Así es como han convertido el problema del plegado de proteínas en un problema de convertir una imagen a otra. Y ojo, esta es la parte de inteligencia artificial. Con esto ya tenemos obtenida cuál es la matriz de distribución de las distancias de cada uno de los aminoácidos dentro de la proteína plegada. Claro, pero esto no es la proteína en 3D. El siguiente paso que han hecho ha sido el de utilizar un algoritmo que conocemos aquí en el canal, el descenso del gradiente, para poco a poco ir optimizando la estructura de la proteína para que ésta se vaya plegando, optimizando los ángulos de torsión, como hacemos con los parámetros de una red neuronal, para que poco a poco la estructura de la proteína vaya haciendo que las distancias entre aminoácidos se parezca a la predicha por la red neuronal. Tras optimizar, el resultado será la estructura tridimensional de la proteína. AlphaFault habrá terminado su trabajo y la proteína estará plegada. Vale, pero ¿qué datos han utilizado para entrenarlo? Lo que ha hecho la gente de Bitmine ha sido tomar muchas de las estructuras de proteínas conocidas que se encuentran en el Protein Data Bank y que se han obtenido utilizando métodos tradicionales más justosos. Y han entrenado al sistema de AlphaFault para que aprendiese a reconocer los patrones que hacen que se pliegue de una forma u otra, obteniendo resultados muy precisos. Para medir la precisión de las predicciones de este plegamiento, la métrica que se utilizó es el llamado GDT o Global Distance Test. El GDT iría del 0 al 100 e indicaría el porcentaje de residuos de aminoácidos que se encontraría en la posición correcta, dentro de un margen de error. Y para que os hagáis una idea de una puntuación de unos 90 GDT aproximadamente, se consideraría un resultado comparable a los métodos actuales, que serían la cristalogracida de rayos X o la resonancia magnética nuclear. Pues de los resultados de este año, AlphaFault obtiene ni más ni menos que una puntuación de 92,4 GDT. Increíble. ¿Qué significa esto? Pues que realmente AlphaFault ha conseguido unos resultados increíbles, ya sea comparándolos con los resultados del segundo mejor equipo en esta competición, o en términos generales comparándolos con los métodos científicos actuales. Y donde la calidad de los resultados nos permite empezar a soñar en utilizar estos métodos computacionales como alternativa a los métodos más clásicos, que son más costosos y requieren de mucho más tiempo. Sobre esto, lo que tenemos que entender de AlphaFault 2 es que la evolución que ha sufrido ha sido la evolución tradicional que hemos visto en el campo del deep learning, en donde los algoritmos basados en mecanismos de atención, como por ejemplo los transformers, han ido ganando popularidad por su potencia. Sabemos que dentro de las tripas de esta versión de AlphaFault 2, existen elementos comunes a los que podemos encontrar en una arquitectura como el transformer, que encontramos en muchos de los grandes modelos del lenguaje actuales como GPT-3. Aquí dejamos que sea el propio modelo el que pueda prestar atención a los diferentes elementos de la secuencia dada como entrada, y también a todas las múltiples secuencias alineadas que hemos mencionado previamente. Utilizando toda esta información, AlphaFault consigue sobresalir en su tarea. Y esto es impresionante, porque si lo pensamos fríamente, lo que ha ocurrido aquí es que un grupo de ingenieros que realmente son expertos en deep learning, han venido con su tecnología a una competición de gente de biología, y han centrado su atención literalmente en resolver este problema concreto. Han sabido adaptar las necesidades de este problema a la tecnología actual que contamos, a los bloques fundamentales que utilizamos en el deep learning, y con ello han conseguido un resultado meteórico. Y con esto me pregunto, ¿cuál es el límite? Siempre que contemos con los datos haciendo uso de una metodología de deep learning, ¿podremos alcanzar resultados como esto? ¿Podemos resolver cualquier reto que la ciencia nos plantee? Pues en concreto en el campo de la biomedicina, conocer la estructura de las proteínas nos puede ayudarnos a entender mejor cómo funciona nuestro organismo, sino también a conocer que hay otras enfermedades que son debidas a mal plegamiento de las proteínas como el Alzheimer, o por ejemplo ayudarnos con el desarrollo de fármacos. Aunque para entender esto y para hablar de esto más largo y tendido tenéis nuestro vídeo, bueno es mi vídeo, está en mi canal, nuestro vídeo, pero ya no queréis que vayáis al otro vídeo del otro canal a verlo. Pero sí que es nuestro vídeo, ahora queda como una bola atrás. O sea, es nuestro vídeo en mi canal, pero es nuestro vídeo. Lo que está claro es que Alpha Fold 2 ha marcado un antes y un después que mucha gente está comparando con lo ocurrido a principios de décadas con ImageNet. Ya lo he comentado en varias ocasiones en el canal, pero la revolución del deep learning que estamos viviendo en esta última década realmente tiene su punto de partida en los resultados tan impresionantes que consiguió un equipo al utilizar esta tecnología por primera vez en la competición de ImageNet. Fue al alcanzar estos impresionantes resultados cuando gran parte de la industria y la academia se vio interesada por esta tecnología, dando paso a todos los avances que hemos visto en visión por ordenador, en modelos generativos, en conducción autónoma, AlphaGo, Transformers y hoy Alpha Fold 2. Muchos comparan ese momento con lo que podría ocurrir ahora en el campo de la biología, siendo la victoria de Alpha Fold 2 un motivo para traer mucho interés en esta tecnología y empezar a aplicarla de manera sistemática para desarrollar nuevos métodos que puedan acelerar la investigación en el plegado de proteínas. Un avance que demuestra cómo campos tan distintos como la inteligencia artificial y la biomedicina al final tienen tanto que aportarse la una a la otra. ¡Pum! Pues ya hemos terminado. ¡Mucho mal de daño! Ya hemos terminado el vídeo y... ¿Has sacado el guión? Pues no, porque todavía queda más contenido. Tenéis otro vídeo entero en el canal de Sandra donde estamos hablando de todo este proteín folding, vamos a explicarlo en más profundidad. Y vamos a hablar de las proteínas y de cómo se pliegan y hacen robotitos y toda la relación que tiene con la informática que nos toca. Ya, ¿no? De hecho... De hecho, voy a aprovechar para enseñar... ¿Por dónde vas? ¡Mirá lo que haces! ¡No se lo he leído! El libro de Sandra Ortonoves, ¿qué puede salir mal? Un libro donde explica todo esto que también vamos a estar hablando en tu vídeo y muchas más cosas sobre biomedicina. Sí, es como que hay varios niveles, o sea, para entender bien todo lo que es este tema plegamiento, proteínas, Alpha Fold, inteligencia artificial y todo esto... ...susto. Tenéis que ver ambos vídeos porque ambos se complementan súper bien y te dan información de cada uno de los campos bastante completa. Pero si queréis saber más de biomedicina y os estáis iniciando en el campo o estéis estudiando una carrera similar o biomedicina tal cual, podéis leer este libro que está, creo, bastante completo. Está mal que lo diga yo, pero... Está fatal. Pero es un muy buen regalo para Navidades ahora que están llegando las Navidades. Y nada más chicos, hasta aquí el vídeo de hoy. Es que no vamos a seguir alargando porque es que la cosa tampoco da para más. Así que ya sabéis, más inteligencia artificial no en el próximo vídeo sino en el canal de Sandra. ¿Algo más que decir? ¿Tú últimas palabras? Un besito. Pues sí. Adiós. ¡Ue! ¡Posad! ...reinvumante, si prestamos atención... ¿Qué haces? No. Joder, es que te voy a editar, yo voy a entrar tú y tú. No, entro... Te voy a hundir la carrera. Pero que lo puedes hacer. No, no, no. A ver, estos son... Vale, vale. Intimidades de los youtubers que cuando graban a cámara. Sandra... Hoy... ¿Qué situación? No puedo. No te jodas por favor. Y esta es la historia. Sí. No. Primera vez. DeepMind con su sistema. DeepMind. DeepMind. DeepMind. Aunque los resultados... Vamos. Cierra la... Y ahí me ven. Venga. Pues en concreto en el mundo. No, el mundo es el queso. Venga.
