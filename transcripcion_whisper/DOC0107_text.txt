 Para entrenar cualquier modelo de Machine Learning tenemos que fijar algo que se conocen como los hiperparámetros, que son unas variables numéricas externas que debemos escoger cuidadosamente para luego obtener el mejor desempeño posible. Así que para cualquier proyecto de Machine Learning tenemos que obtener ese set de hiperparámetros ideal que nos permita generar las mejores predicciones posibles para el modelo que estemos entrenando y para el problema que queramos resolver. Este proceso se conoce precisamente con el nombre de ajuste de hiperparámetros y existen esencialmente dos enfoques para lograr este objetivo, la búsqueda exhaustiva o grid search y la búsqueda aleatoria o random search. Así que en este video vamos a entender en detalle qué es este ajuste de hiperparámetros y cómo funcionan estos dos métodos que les acabo de mencionar. Pero antes de comenzar los invito a visitar codificandobits.com en donde encontrarán la Academia Online con cursos de Inteligencia Artificial, Ciencia de Datos y Machine Learning que les permitirán construir su carrera en estas áreas y todo por una suscripción mensual de tan solo 10 dólares. Además se podrán poner en contacto conmigo si están interesados en asesorías para el desarrollo de proyectos o cursos de formación personalizada. Así que listo, comencemos. Comencemos recordando qué son los hiperparámetros de un modelo de lo cual ya hablamos en detalle en un video anterior. Supongamos que queremos construir una red neuronal para una empresa de streaming de video. La idea es tomar el perfil de cada cliente, como el número de meses que lleva suscrito al servicio, la cantidad de horas por semana que accede a la plataforma, la edad del cliente y su ubicación geográfica entre otras y queremos que la red aprenda a predecir si el cliente permanecerá o abandonará el servicio. Una de las decisiones que tenemos que tomar en este caso es por ejemplo determinar cuántas capas debemos agregar a esta red neuronal y cuántas neuronas tenemos que agregarle a cada una de esas capas. Estas variables son precisamente algunos hiperparámetros de esta red neuronal. Así que los hiperparámetros son en esencia unos valores numéricos externos que nosotros debemos definir al momento de escribir el código para crear esa red neuronal o ese modelo de Machine Learning. Volvamos al problema anterior y supongamos que definimos estos posibles valores para los hiperparámetros de la red neuronal. Un número de capas ocultas igual a 1 o 2. Si tenemos solo una capa oculta podremos usar 20 o 10 neuronas y si tenemos dos capas ocultas en la segunda capa podremos ubicar 10 o 5 neuronas. Y acá vale la pena preguntarnos cómo podemos determinar ese número de capas ocultas y ese número de neuronas por capa de la red neuronal. Y esta pregunta es fundamental, pues el desempeño del modelo estará precisamente relacionado con el valor que escojamos para estos hiperparámetros. Esto quiere decir que para ciertas combinaciones de capas ocultas y de número de neuronas por capa tendremos unas predicciones relativamente malas, pero para otras combinaciones podremos obtener predicciones muchísimo mejores. Desafortunadamente no existe algo así como una fórmula matemática mágica que nos permita encontrar el valor ideal de esos hiperparámetros, pues estos dependen del modelo que estemos utilizando y también de los datos. Y como cada problema tiene un set de datos totalmente diferente, pues resulta imposible tener una fórmula que funcione adecuadamente para todos los modelos y tipos de datos. Así que en la práctica lo que se hace es usar un enfoque de prueba y error, es decir, tomamos diferentes combinaciones de hiperparámetros, entrenamos y validamos el modelo con cada una de esas combinaciones, determinamos su desempeño y de todas las pruebas que hagamos escogemos aquel modelo y aquel set de hiperparámetros que nos genere el mejor desempeño posible. Y esto se conoce precisamente como el ajuste de hiperparámetros. Así que este ajuste de hiperparámetros es un proceso de prueba y error que dependiendo de las combinaciones que estemos probando nos permite encontrar el set de hiperparámetros más adecuado para el modelo y para los datos que estemos usando. Y para realizar este ajuste de hiperparámetros generalmente usamos uno de estos dos enfoques, la búsqueda exhaustiva que también se conoce en inglés como grid search y la búsqueda aleatoria que se conoce como random search. Así que vamos en detalle en qué consisten estos dos métodos. La idea de la búsqueda exhaustiva es sencilla, simplemente debemos probar todas las posibles combinaciones de hiperparámetros, es decir que para cada una de esas combinaciones entrenamos y validamos el modelo, calculamos su desempeño y al final elegimos la combinación que nos arroje el mejor desempeño posible. Entendamos esta idea volviendo a nuestro ejemplo de la red neuronal. Habíamos mencionado anteriormente que tenemos estas opciones de hiperparámetros, un número de capas ocultas igual a 1 o 2, un número de neuronas en la primera capa de 20 o 10 y un número de neuronas en la segunda capa de 10 o 5. Teniendo esto en cuenta podríamos tener en total seis combinaciones de hiperparámetros. En la primera podemos tener una capa oculta con 20 neuronas, en la segunda usaríamos una capa oculta pero con 10 neuronas, en la tercera tendríamos dos capas ocultas, la primera con 20 neuronas y la segunda con 10. En la cuarta combinación tendríamos dos capas ocultas, similar al caso anterior pero la primera capa tendría 20 neuronas, mientras que la segunda tendría 5. En la quinta combinación tendríamos dos capas ocultas, ambas con 10 neuronas. Y por último en la sexta combinación tendríamos dos capas ocultas, la primera con 10 neuronas y la segunda con 5. Ahora la idea es entrenar y validar la red neuronal con cada una de estas seis combinaciones por aparte, es decir, hacer el entrenamiento y la validación por aparte un total de seis veces. Para este entrenamiento y validación podemos usar los sets de entrenamiento, validación y prueba o la validación cruzada. De estos métodos ya hablen detalle en videos anteriores, así que les dejo el enlace en la descripción para que los revisen. Supongamos además que vamos a medir el desempeño del modelo como el porcentaje de aciertos al momento de determinar si un suscriptor permanece o abandona nuestro servicio. Así un desempeño del 95% nos dice que de cada 100 usuarios que analizamos, en 95% de estos casos el modelo predice correctamente el estado de ese usuario. Pues bien, supongamos que entrenamos la red con la primera combinación de hiperparámetros y obtenemos un desempeño del 92%. Hacemos lo mismo con la segunda combinación y obtenemos un 87%. Y repetimos esto para las cuatro combinaciones de hiperparámetros restantes, obteniendo desempeños de 91%, 96%, 88% y 92% respectivamente. Terminado este procedimiento, lo único que nos queda es elegir el set de hiperparámetros para el cual se obtuvo el mejor desempeño. En este caso esta sería la cuarta combinación, es decir la red con dos capas ocultas, la primera con 20 neuronas y la segunda con 5. Pues dicha combinación nos entrega el desempeño más alto que es del 96%. Y listo, esta es la idea básica de la búsqueda exhaustiva. La ventaja de este método es que al probar todas las combinaciones al final estaremos 100% seguros de que la combinación seleccionada es la mejor de todas las posibles y por tanto el modelo seleccionado será el mejor de todos. Sin embargo la desventaja es que si tenemos un modelo muy complejo y demasiados datos, el entrenamiento y validación con cada una de esas combinaciones requerirá demasiado tiempo y demasiados recursos computacionales. Así que como alternativa a este inconveniente tenemos el método de random search o búsqueda aleatoria. El principal inconveniente de la búsqueda exhaustiva que vemos anteriormente es que se tienen que probar todas las posibles combinaciones de hiperparámetros, lo que puede llegar a dificultar ese proceso de ajuste de hiperparámetros. Entonces como alternativa a este método tenemos precisamente la búsqueda aleatoria que lo que hace es en lugar de tomar todas las posibles combinaciones de hiperparámetros, selecciona una muestra aleatoria de esas posibles combinaciones, entrena y valida el modelo con esa muestra aleatoria, luego calcula el desempeño y elige el más adecuado de entre todas las muestras analizadas. Para entender cómo funciona este método volvamos una vez más a nuestro ejemplo de la red neuronal. Habíamos mencionado que existen seis posibles combinaciones de hiperparámetros, una capa oculta con 20 neuronas, una capa oculta con 10 neuronas, dos capas ocultas con 20 y 10 neuronas, dos capas ocultas con 20 y 5 neuronas, dos capas con 10 neuronas cada una o dos capas ocultas con 10 y 5 neuronas. Así que en este caso en lugar de analizar las seis posibles combinaciones, seleccionaremos por ejemplo una muestra aleatoria de tres. Digamos que estas son las combinaciones 1, 4 y 6. Una vez seleccionadas estas combinaciones lo que hacemos es entrenar y validar el modelo con cada una de ellas, y al hacerlo obtendremos desempeños de 92, 96 y 92 por ciento. Y una vez evaluados estos desempeños, lo único que nos queda es elegir la mejor combinación, es decir aquella con el desempeño más alto, que en este caso es la cuarta con un desempeño del 96 por ciento, y que corresponde a una red neuronal con dos capas ocultas con 25 neuronas cada una. Y listo, así es como funciona el método de búsqueda aleatoria para el ajuste de hiperparámetros, y la ventaja de este método es evidente comparado con la búsqueda exhaustiva, pues al probar menos combinaciones de hiperparámetros requeriremos menos tiempo de entrenamiento y validación, y menos recursos computacionales, pero la desventaja está en que al seleccionar aleatoriamente una parte de esas posibles combinaciones, no siempre podremos garantizar que dentro de la muestra seleccionada estará esa combinación ideal de hiperparámetros que genere el mejor desempeño posible. Muy bien, acabamos de ver en qué consiste el ajuste de hiperparámetros, que en esencia nos permite encontrar ese set de hiperparámetros que genera las mejores predicciones posibles para el modelo que estemos construyendo, y para lograr esto podemos generalmente usar uno de dos enfoques, la búsqueda exhaustiva que analiza todas las posibles combinaciones de hiperparámetros, y la búsqueda aleatoria que analiza una muestra aleatoria de todas esas posibles combinaciones. La búsqueda exhaustiva nos permite garantizar que al final del proceso vamos a encontrar ese set óptimo de hiperparámetros para construir el modelo, pero va a requerir mucho más tiempo de entrenamiento y más recursos computacionales, mientras que la búsqueda aleatoria será más rápida, va a requerir menos recursos, pero no siempre nos va a garantizar llegar a esa solución óptima en términos de los hiperparámetros. Así que la elección que hagamos va a depender precisamente de esos recursos computacionales, si tenemos tiempo suficiente y muchos recursos podríamos usar la búsqueda exhaustiva, o de lo contrario podríamos considerar la búsqueda aleatoria. Sin embargo, en proyectos reales con modelos muy complejos, con muchos hiperparámetros y muchos datos, generalmente el enfoque de búsqueda aleatoria funciona bastante bien, y es el que les recomiendo para sus proyectos. Bien, ya saben que si tienen algún adudó o comentario lo pueden dejar acá abajo, y recuerden que si les gustó el vídeo los invito a darle un pulgar hacia arriba de me gusta y a compartirlo con sus amigos y conocidos, pues ya saben que esto me ayudará a llegar con este contenido a cada vez más y más personas, y si aún no lo han hecho los invito a suscribirse al canal y activar las notificaciones para que youtube les avise cada vez que publique nuevos vídeos acá en el canal. Por ahora esto es todo, les envío un saludo y nos vemos en el próximo vídeo.
